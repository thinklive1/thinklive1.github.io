<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.24/fancybox/fancybox.css" integrity="sha256-vQkngPS8jiHHH0I6ABTZroZk8NPZ7b+MUReOFE9UsXQ=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"thinklive1.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":true,"color":"#66CCFF","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":true,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="计算机安全常识 账户安全 美国国家标准与技术研究院(NIST)的建议：  密码长度应至少为八个字符 验证者应规定所有打印的 ASCII 字符和 Unicode 符号的长度最多为 64 个字符 验证者应该将预期的密码与可用的字典单词、重复序列、被破坏的密码列表和上下文特定的单词进行比较 验证者不应允许未经身份验证的用户访问密码提示 验证者不应要求定期更改密码 验证者应限制失败的身份验证尝试次数并锁定">
<meta property="og:type" content="article">
<meta property="og:title" content="基于哈佛cs50的计算机通识笔记">
<meta property="og:url" content="https://thinklive1.github.io/thinklive/16959/index.html">
<meta property="og:site_name" content="thinklive">
<meta property="og:description" content="计算机安全常识 账户安全 美国国家标准与技术研究院(NIST)的建议：  密码长度应至少为八个字符 验证者应规定所有打印的 ASCII 字符和 Unicode 符号的长度最多为 64 个字符 验证者应该将预期的密码与可用的字典单词、重复序列、被破坏的密码列表和上下文特定的单词进行比较 验证者不应允许未经身份验证的用户访问密码提示 验证者不应要求定期更改密码 验证者应限制失败的身份验证尝试次数并锁定">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/0/alphabeta.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/mastermind3.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/modusponens.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/implicationelimination.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/demorgans1.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/demorgans2.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/distributive1.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/1/distributive2.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/2/bayesiannetwork.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/2/inferencebyenumeration.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/2/transitionmodel.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/2/sensormodel.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/3/constraintsatisfaction1.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/3/constraintsatisfaction2.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/nearestneighbor.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/decisionboundary.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/supportvector.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/circleboundary.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/regression.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/overfitting.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/4/reinforcement.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2024/notes/4/markov.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/nnstructure.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/weather.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/multilayer.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/deepnn.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/dropout.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/convolution.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/kernel.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/convolutionalnn.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/5/recurrent.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/6/syntactictree.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/6/bayesrule.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/6/naivebayes.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/6/idf.png">
<meta property="og:image" content="https://cs50.harvard.edu/ai/2020/notes/6/sgarchitecture.png">
<meta property="article:published_time" content="2025-02-28T13:12:21.000Z">
<meta property="article:modified_time" content="2025-09-29T10:38:40.595Z">
<meta property="article:author" content="thinklive">
<meta property="article:tag" content="课程笔记">
<meta property="article:tag" content="python">
<meta property="article:tag" content="哈佛">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="计算机安全">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cs50.harvard.edu/ai/2020/notes/0/alphabeta.png">


<link rel="canonical" href="https://thinklive1.github.io/thinklive/16959/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://thinklive1.github.io/thinklive/16959/","path":"thinklive/16959/","title":"基于哈佛cs50的计算机通识笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>基于哈佛cs50的计算机通识笔记 | thinklive</title>
  







<script type="text/javascript" async src="/js/fairyDustCursor.js"></script>
<script type="text/javascript" async src="/js/tab-title.js"></script>
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>
<script src="/js/tab-title.js"></script>

<!--pjax：防止跳转页面音乐暂停-->
<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script>
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
  <script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>
<script>
const options = {
  bottom: '64px', // default: '32px'
  right: 'unset', // default: '32px'
  left: '32px', // default: 'unset'
  time: '0.5s', // default: '0.3s'
  mixColor: '#fff', // default: '#fff'
  backgroundColor: '#fff',  // default: '#fff'
  buttonColorDark: '#100f2c',  // default: '#100f2c'
  buttonColorLight: '#fff', // default: '#fff'
  saveInCookies: false, // default: true,
  label: '🌓', // default: ''
  autoMatchOsTheme: true // default: true
}

const darkmode = new Darkmode(options);
</script>
<!-- hexo injector head_end start --><script> let HEXO_MMEDIA_DATA = { js: [], css: [], aplayerData: [], metingData: [], artPlayerData: [], dplayerData: []}; </script><!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="thinklive" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>
<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>


  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">thinklive</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">dirichlet library</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索 | search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-主页-|-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页 | home</a></li><li class="menu-item menu-item-标签-|-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签 | tags</a></li><li class="menu-item menu-item-分类-|-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类 | categories</a></li><li class="menu-item menu-item-归档-|-archive"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档 | archive</a></li><li class="menu-item menu-item-相册-|-photo"><a href="/photos/" rel="section"><i class="fa fa-camera fa-fw"></i>相册 | photo</a></li><li class="menu-item menu-item-留言-|-guestbook"><a href="/guestbook/" rel="section"><i class="fa fa-book fa-fw"></i>留言 | guestbook</a></li><li class="menu-item menu-item-感谢-|-thank"><a href="/thanks/" rel="section"><i class="fa custom thanks fa-fw"></i>感谢 | thank</a></li><li class="menu-item menu-item-游戏-|-game"><a href="/game/bad1.html" rel="section"><i class="fa fa-gamepad fa-fw"></i>游戏 | game</a></li><li class="menu-item menu-item-神龛-|-shrine"><a href="/cyberblog/" rel="section"><i class="fa fa-microchip fa-fw"></i>神龛 | shrine</a></li><li class="menu-item menu-item-资源地图-|-resourcemap"><a href="/webstack/" rel="section"><i class="fa fa-list fa-fw"></i>资源地图 | resourcemap</a></li><li class="menu-item menu-item-思维导图-|-mindmap"><a href="/mindmap/index.html" rel="section"><i class="fa fa-map fa-fw"></i>思维导图 | mindmap</a></li><li class="menu-item menu-item-网站地图-|-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>网站地图 | sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索 | search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">


<!--网易云音乐插件-->
<!-- require APlayer -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script>
<!-- require MetingJS-->
<script src="https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js"></script> 
<!--网易云playlist外链地址-->   
<meting-js
    server="netease"
    type="playlist" 
    id="2762741085"
    mini="false"
    fixed="false"
    list-folded="true"
    autoplay="false"
    volume="0.2"
    theme="#4c4c4c"
    order="random"
    loop="all"
    preload="auto"
    mutex="true">
    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AE%89%E5%85%A8%E5%B8%B8%E8%AF%86"><span class="nav-number">1.</span> <span class="nav-text">计算机安全常识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B4%A6%E6%88%B7%E5%AE%89%E5%85%A8"><span class="nav-number">1.1.</span> <span class="nav-text">账户安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8"><span class="nav-number">1.2.</span> <span class="nav-text">数据安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8"><span class="nav-number">1.3.</span> <span class="nav-text">系统安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8"><span class="nav-number">1.4.</span> <span class="nav-text">软件安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%90%E7%A7%81%E5%AE%89%E5%85%A8"><span class="nav-number">1.5.</span> <span class="nav-text">隐私安全</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">2.</span> <span class="nav-text">人工智能</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%9C%E7%B4%A2-search"><span class="nav-number">2.1.</span> <span class="nav-text">搜索 search</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%8A%97%E6%80%A7%E6%90%9C%E7%B4%A2-adversarial-search"><span class="nav-number">2.1.1.</span> <span class="nav-text">对抗性搜索 Adversarial Search</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#alpha-beta-%E4%BF%AE%E5%89%AA-alpha-beta-pruning"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">Alpha-Beta 修剪 Alpha-Beta Pruning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E9%99%90%E5%88%B6-depth-limited-minimax"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">深度限制 Depth-Limited Minimax</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86-knowledge"><span class="nav-number">2.2.</span> <span class="nav-text">知识 knowledge</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A8%E7%90%86-inference"><span class="nav-number">2.2.1.</span> <span class="nav-text">推理 Inference</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E5%B7%A5%E7%A8%8B-knowledge-engineering"><span class="nav-number">2.2.2.</span> <span class="nav-text">知识工程 Knowledge Engineering</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A8%E7%90%86%E8%A7%84%E5%88%99-inference-rules"><span class="nav-number">2.2.3.</span> <span class="nav-text">推理规则 Inference Rules</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E7%8E%87-uncertainty"><span class="nav-number">2.3.</span> <span class="nav-text">概率 Uncertainty</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%87%E6%A0%B7-sampling"><span class="nav-number">2.3.1.</span> <span class="nav-text">采样 Sampling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B-markov-models"><span class="nav-number">2.3.2.</span> <span class="nav-text">马尔可夫模型 Markov Models</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96-optimization"><span class="nav-number">2.4.</span> <span class="nav-text">优化 Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%A6%E6%9D%9F%E6%BB%A1%E8%B6%B3-constraint-satisfaction"><span class="nav-number">2.4.1.</span> <span class="nav-text">约束满足 Constraint Satisfaction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E6%BA%AF%E6%90%9C%E7%B4%A2-backtracking-search"><span class="nav-number">2.4.2.</span> <span class="nav-text">回溯搜索 Backtracking Search</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-machine-learning"><span class="nav-number">2.5.</span> <span class="nav-text">机器学习 Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-supervised-learning"><span class="nav-number">2.5.1.</span> <span class="nav-text">监督学习 Supervised Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AD%A6%E4%B9%A0-perceptron-learning"><span class="nav-number">2.5.1.1.</span> <span class="nav-text">感知机学习 Perceptron Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-support-vector-machines"><span class="nav-number">2.5.1.2.</span> <span class="nav-text">支持向量机 Support Vector Machines</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92-regression"><span class="nav-number">2.5.1.3.</span> <span class="nav-text">回归 Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-loss-functions"><span class="nav-number">2.5.1.4.</span> <span class="nav-text">损失函数 Loss Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88-overfitting"><span class="nav-number">2.5.1.5.</span> <span class="nav-text">过拟合 Overfitting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96-regularization"><span class="nav-number">2.5.1.6.</span> <span class="nav-text">正则化 Regularization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-reinforcement-learning"><span class="nav-number">2.5.2.</span> <span class="nav-text">强化学习 Reinforcement Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-markov-decision-processes"><span class="nav-number">2.5.2.1.</span> <span class="nav-text">马尔可夫决策过程 Markov Decision Processes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#q-%E5%AD%A6%E4%B9%A0-q-learning"><span class="nav-number">2.5.2.2.</span> <span class="nav-text">Q 学习 Q-Learning</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-unsupervised-learning"><span class="nav-number">2.5.3.</span> <span class="nav-text">无监督学习 Unsupervised Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#k-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB-k-means-clustering"><span class="nav-number">2.5.3.1.</span> <span class="nav-text">K-均值聚类 k-means Clustering</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-neural-networks"><span class="nav-number">2.6.</span> <span class="nav-text">神经网络 Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-activation-functions"><span class="nav-number">2.6.1.</span> <span class="nav-text">激活函数 Activation Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-neural-network-structure"><span class="nav-number">2.6.2.</span> <span class="nav-text">神经网络结构 Neural Network Structure</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-gradient-descent"><span class="nav-number">2.6.3.</span> <span class="nav-text">梯度下降 Gradient Descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-multilayer-neural-networks"><span class="nav-number">2.6.4.</span> <span class="nav-text">多层神经网络 Multilayer Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%BC%94%E7%AE%97%E6%B3%95-backpropagation"><span class="nav-number">2.6.4.1.</span> <span class="nav-text">反向传播演算法 Backpropagation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88-overfitting-1"><span class="nav-number">2.6.5.</span> <span class="nav-text">过拟合 Overfitting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-computer-vision"><span class="nav-number">2.6.6.</span> <span class="nav-text">计算机视觉 Computer Vision</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF-image-convolution"><span class="nav-number">2.6.6.1.</span> <span class="nav-text">图像卷积 Image Convolution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-convolutional-neural-networks"><span class="nav-number">2.6.6.2.</span> <span class="nav-text">卷积神经网络 Convolutional Neural Networks</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-recurrent-neural-networks"><span class="nav-number">2.6.7.</span> <span class="nav-text">循环神经网络 Recurrent Neural Networks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-natural-language-processing"><span class="nav-number">2.7.</span> <span class="nav-text">自然语言处理 Natural Language Processing</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%A5%E6%B3%95%E5%92%8C%E8%AF%AD%E4%B9%89-syntax-and-semantics"><span class="nav-number">2.7.1.</span> <span class="nav-text">句法和语义 Syntax and Semantics</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E8%AF%AD%E6%B3%95-context-free-grammar"><span class="nav-number">2.7.1.1.</span> <span class="nav-text">上下文无关语法 Context-Free Grammar</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#n-%E5%85%83%E8%AF%AD%E6%B3%95-n-grams"><span class="nav-number">2.7.1.2.</span> <span class="nav-text">n 元语法 n-grams</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%87%E8%AE%B0%E5%8C%96-tokenization"><span class="nav-number">2.7.1.3.</span> <span class="nav-text">标记化 Tokenization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B-markov-models-1"><span class="nav-number">2.7.1.4.</span> <span class="nav-text">马尔可夫模型 Markov Models</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B-bag-of-words-model"><span class="nav-number">2.7.2.</span> <span class="nav-text">词袋模型 Bag-of-Words Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#naive-bayes"><span class="nav-number">2.7.2.1.</span> <span class="nav-text">Naive Bayes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-information-retrieval"><span class="nav-number">2.7.2.2.</span> <span class="nav-text">信息检索 Information Retrieval</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96-information-extraction"><span class="nav-number">2.7.3.</span> <span class="nav-text">信息提取 Information Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%8D%E7%BD%91-word-net"><span class="nav-number">2.7.3.1.</span> <span class="nav-text">词网 Word Net</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%8D%E6%B1%87%E8%A1%A8%E5%BE%81-word-representation"><span class="nav-number">2.7.3.2.</span> <span class="nav-text">词汇表征 Word Representation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#word2vec"><span class="nav-number">2.7.3.3.</span> <span class="nav-text">word2vec</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="thinklive"
      src="/images/thive.png">
  <p class="site-author-name" itemprop="name">thinklive</p>
  <div class="site-description" itemprop="description">起初，世界是一团思索，它向所有的方向迈了一步，于是万物由此而生</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">45</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/thinklive1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thinklive1" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/t469631989@gmail.com" title="E-Mail → t469631989@gmail.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/38099250?spm_id_from=333.1007.0.0" title="bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;38099250?spm_id_from&#x3D;333.1007.0.0" rel="noopener me" target="_blank"><i class="fa custom bilibili fa-fw"></i>bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/id/thinkliving" title="steam → https:&#x2F;&#x2F;steamcommunity.com&#x2F;id&#x2F;thinkliving" rel="noopener me" target="_blank"><i class="fa custom steam fa-fw"></i>steam</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
  </div>

<div style="Text-align:center;width:100%"><div style="margin:0 auto"><canvas id="canvas" style="width:60%" height="100" width="700">当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>!function(){function t(t,e){for(var a=0;a<l[e].length;a++)for(var n=0;n<l[e][a].length;n++)1==l[e][a][n]&&(h.beginPath(),h.arc(14*(g+2)*t+2*n*(g+1)+(g+1),2*a*(g+1)+(g+1),g,0,2*Math.PI),h.closePath(),h.fill())}function e(){var t=[],e=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),a=[];a.push(e[1],e[2],10,e[3],e[4],10,e[5],e[6]);for(var r=c.length-1;r>=0;r--)a[r]!==c[r]&&t.push(r+"_"+(Number(c[r])+1)%10);for(var r=0;r<t.length;r++)n.apply(this,t[r].split("_"));c=a.concat()}function a(){for(var t=0;t<d.length;t++)d[t].stepY+=d[t].disY,d[t].x+=d[t].stepX,d[t].y+=d[t].stepY,(d[t].x>i+g||d[t].y>f+g)&&(d.splice(t,1),t--)}function n(t,e){for(var a=[1,2,3],n=["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"],r=0;r<l[e].length;r++)for(var o=0;o<l[e][r].length;o++)if(1==l[e][r][o]){var h={x:14*(g+2)*t+2*o*(g+1)+(g+1),y:2*r*(g+1)+(g+1),stepX:Math.floor(4*Math.random()-2),stepY:-2*a[Math.floor(Math.random()*a.length)],color:n[Math.floor(Math.random()*n.length)],disY:1};d.push(h)}}function r(){o.height=100;for(var e=0;e<c.length;e++)t(e,c[e]);for(var e=0;e<d.length;e++)h.beginPath(),h.arc(d[e].x,d[e].y,g,0,2*Math.PI),h.fillStyle=d[e].color,h.closePath(),h.fill()}var l=[[[0,0,1,1,1,0,0],[0,1,1,0,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,0,1,1,0],[0,0,1,1,1,0,0]],[[0,0,0,1,1,0,0],[0,1,1,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[1,1,1,1,1,1,1]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,0,0,1,1],[1,1,1,1,1,1,1]],[[1,1,1,1,1,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,0,1,1,1,0],[0,0,1,1,1,1,0],[0,1,1,0,1,1,0],[1,1,0,0,1,1,0],[1,1,1,1,1,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,1,1]],[[1,1,1,1,1,1,1],[1,1,0,0,0,0,0],[1,1,0,0,0,0,0],[1,1,1,1,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[1,1,1,1,1,1,1],[1,1,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,1,1,0,0,0,0]],[[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0]]],o=document.getElementById("canvas");if(o.getContext){var h=o.getContext("2d"),f=100,i=700;o.height=f,o.width=i,h.fillStyle="#f00",h.fillRect(10,10,50,50);var c=[],d=[],g=o.height/20-1;!function(){var t=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date);c.push(t[1],t[2],10,t[3],t[4],10,t[5],t[6])}(),clearInterval(v);var v=setInterval(function(){e(),a(),r()},50)}}()</script></div>
<img class= 'logo' src="/images/thinklive_cyber.png"; z-index: '0'; style="max-width: 100%; width: auto; height: auto;background-color: --content-bg-color;">

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://thinklive1.github.io/thinklive/16959/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/thive.png">
      <meta itemprop="name" content="thinklive">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinklive">
      <meta itemprop="description" content="起初，世界是一团思索，它向所有的方向迈了一步，于是万物由此而生">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="基于哈佛cs50的计算机通识笔记 | thinklive">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于哈佛cs50的计算机通识笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-28 21:12:21" itemprop="dateCreated datePublished" datetime="2025-02-28T21:12:21+08:00">2025-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-29 18:38:40" itemprop="dateModified" datetime="2025-09-29T18:38:40+08:00">2025-09-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">课程笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%80%9A%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">通识</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>18k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:07</span>
    </span>
</div>

        
        </div>
      </header>
   

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="计算机安全常识">计算机安全常识</h1>
<h2 id="账户安全">账户安全</h2>
<p>美国国家标准与技术研究院(NIST)的建议：</p>
<ul>
<li>密码长度应至少为八个字符</li>
<li>验证者应规定所有打印的 ASCII 字符和 Unicode 符号的长度最多为 64 个字符</li>
<li>验证者应该将预期的密码与可用的字典单词、重复序列、被破坏的密码列表和上下文特定的单词进行比较</li>
<li>验证者不应允许未经身份验证的用户访问密码提示</li>
<li>验证者不应要求定期更改密码</li>
<li>验证者应限制失败的身份验证尝试次数并锁定潜在的攻击者</li>
</ul>
<span id="more"></span>
<p>多重身份验证(2fa)由三个组成部分组成。</p>
<ul>
<li>知识：只有你知道的东西</li>
<li>所有物：仅由授权用户拥有的物品或设备</li>
<li>固有物：仅是您可以获得的一个因素，例如您的指纹、面部或其他生物识别信息</li>
</ul>
<p>一次性密码 OTP:</p>
<ul>
<li>人们可以获得一种特殊的密钥卡或提供一次性密码的设备</li>
<li>OTP 通常是从设备或应用程序获取的</li>
<li>基于短信的 OTP 很容易通过 SIM 交换而被欺骗，攻击者会获取并克隆 SIM 卡并访问您的短信, 因此验证器类型的验证应用程序更安全(比如需要指纹验证的)</li>
</ul>
<p>键盘记录：</p>
<ul>
<li>用户名、密码和 OTP 很容易被攻击者记录您的击键</li>
<li>键盘记录是通过在计算机上安装恶意软件来完成的</li>
<li>最好确保您仅登录您只能访问的设备</li>
</ul>
<p>社会工程/钓鱼：</p>
<ul>
<li>懂得都懂，点击 url 时需要谨慎再谨慎，收到任何可能泄露信息的请求时核对对方身份</li>
</ul>
<p>单点登录 SSO:</p>
<ul>
<li>SSO 允许您使用 Google 或 Facebook 登录来访问 Google 或 Facebook 未提供的服务</li>
<li>因此，您能够以更少的摩擦和更高的安全性轻松访问其他服务</li>
</ul>
<p>密码管理器：</p>
<ul>
<li>把鸡蛋放在一个篮子里，但是相对能提高安全性</li>
<li>推荐 keepass</li>
</ul>
<h2 id="数据安全">数据安全</h2>
<p>哈希：将一些纯文本转换为可读性较差的散列值输出的方法，常存储密码的哈希值从而降低风险</p>
<ul>
<li><em>字典攻击</em> 仍然可以将字典中的一个又一个值输入到哈希函数中，作为破解它的一种方式。</li>
<li><em>彩虹表</em> 是另一种威胁，对手拥有哈希表中所有潜在哈希值的表。然而，这需要数 TB（甚至 PB）的存储容量才能完成</li>
<li><em>单向哈希函数</em> 用代码编写，接收任意长度的字符串并输出固定长度的哈希值。</li>
<li>利用这样的功能，哈希值和哈希函数的持有者将永远不会知道原始密码。</li>
</ul>
<p>盐：<em>加盐</em> 是将附加值“撒”到哈希函数中，从而使哈希值发生变化的过程，几乎可以保证用户提供的哈希值（即使是具有相同密码的用户）也会收到不同的哈希密码</p>
<p>非对称加密：你需要一个公钥一个私钥，例如公钥是两个素数的乘积，私钥是其中一个因数，私钥被收发双方共用</p>
<ul>
<li>发送者使用公钥和明文并将其输入算法中。这会产生密文</li>
<li>接收者将私钥和密文输入到算法中。这会产生破译的文本</li>
<li>消息（文档的内容）被传递给哈希函数，从而产生哈希值，私钥和哈希值被传递给数字签名算法，从而产生数字签名；接收者将公钥和提供给解密算法的签名传递给解密算法，从而产生应与先前计算的哈希值相匹配的哈希值，验证签名</li>
</ul>
<p>硬盘加密：</p>
<ul>
<li>操作系统删除文件时，事实上只释放了空间，原有文件内容有可能留存一段时间，因此需要 <em>安全删除</em> ，将已删除文件的所有剩余部分更改为零、一或零和一的随机序列</li>
<li><em>全盘加密</em> 或 <em>静态加密</em> 可完全加密硬盘驱动器的内容。</li>
<li>如果您的设备被盗或您出售了设备，任何人都将无法访问您的加密数据。</li>
<li>然而，它的缺点是，如果您丢失密码或脸部发生足够大的变化，您将无法访问您的数据。</li>
<li>另一个缺点是黑客可能通过 <em>勒索软件</em> 使用相同类型的技术来加密您的硬盘并将其劫为人质</li>
<li>例如 veracrypt 之类的软件可以实现硬盘级或者文件级(将一个文件虚拟成硬盘分区)的加密，微软的 bitlock 配合部分硬件功能甚至可以实现硬件级加密(范围是卷)</li>
</ul>
<p>量子计算：新兴的计算机技术，可能彻底颠覆目前的计算机密码学</p>
<h2 id="系统安全">系统安全</h2>
<ul>
<li><em>超文本传输​​协议</em> （ <em>HTTP</em> ）是一种未加密的数据传输方式。</li>
<li>使用 HTTP，人们很容易受到 <em>中间人</em> 攻击，攻击者可能会在下载的内容中注入额外的 HTML 代码。广告可以被注入到您通过 HTTP 访问的所有网页中。此外，还可以插入恶意代码。</li>
<li>事实上，还存在其他威胁。 <em>数据包嗅探</em> 是攻击者查看双方之间传输的数据内部的一种方式。可以想象，放置在不安全数据包中的信用卡号会被攻击者检测到并窃取。</li>
<li><em>Cookie</em> 是网站放置在您计算机上的小文件。网站可能会使用 Cookie 来跟踪您的身份、显示您的电子邮件或跟踪您的购物车。 Cookie 使人容易受到 <em>会话劫持</em> ，对手可以通过注入 <em>超级 cookie</em> 来跟踪您。</li>
<li><em>HTTPS</em> 是 HTTP 的安全协议。传输中加密流量(使用上一章提及的公钥加密技术)</li>
<li><em>CA</em> 是颁发证书的受信任的第三方公司</li>
<li>当访问网站时，浏览器会下载该网站的证书，并创建哈希值。</li>
<li>然后，它使用网站的公钥和提供给算法的证书签名来验证哈希值是否符合</li>
<li>如果哈希匹配，则网络浏览器应用程序确信这是一个安全网站</li>
<li><em>SSL Stripping</em> 是一种攻击者在网站上使用 HTTP 将流量重定向到恶意网站的攻击。攻击者甚至可能将其重定向到非预期网站的 HTTPS 安全域。</li>
<li>减轻这种威胁的一种方法是实施 <em>HSTS</em> 或 <em>HTTP 严格传输安全</em> ，服务器告诉浏览器将所有流量引导到安全连接</li>
<li>攻击者可能会对服务器进行 <em>端口扫描</em> ，尝试所有潜在端口以查看它们是否正在接受流量</li>
<li>防火墙是一种软件，通过阻止未经授权的访问（包括设备上受损的服务）来保护各种服务</li>
<li>防火墙利用 <em>IP 地址</em> （分配给网络上每台计算机的唯一编号）来防止外部人员攻击</li>
<li>防火墙还可以使用 <em>深度数据包检查</em> ，检查数据包中的数据以查找您的公司可能感兴趣的材料。这可以用来检查您是否正在向媒体或可能被您公司视为对手的其他方发送电子邮件。</li>
<li>使用 <em>深度数据包检测通过代理</em> ，其中中间的设备用作流量传入和传出网络的路径。您的学校或公司可能会在此代理上更改 URL、记录您尝试浏览的 URL，并希望保护您免受潜在有害行为的影响。</li>
<li><em>蠕虫病毒</em> 是一种恶意软件，可以通过安全漏洞从一台计算机转移到另一台计算机。</li>
<li><em>僵尸网络</em> 是一种恶意软件，一旦安装在您的计算机上，就会感染其他计算机，并且攻击者可以利用它向数千台受感染的计算机发出命令。</li>
<li>受僵尸网络感染的计算机可用于发出 <em>拒绝服务攻击 dos</em> ，从而可以向服务器发出大量请求，以减慢或关闭服务器。由于僵尸网络中有如此多的计算机，因此这种类型的攻击可以称为 <em>分布式拒绝服务攻击 ddos</em></li>
<li><em>零日攻击</em> ，这种攻击会在杀毒软件公司有机会创建修复程序之前利用软件中的未知漏洞</li>
</ul>
<h2 id="软件安全">软件安全</h2>
<ul>
<li>攻击者可能会利用您不注意的情况，声称您正在链接到一个网页，而实际上您正在链接到另一个网页，如 <code>&lt;a href="https://yale.edu"&gt;https://harvard.edu&lt;/a&gt;</code></li>
<li>攻击者经常创建虚假版本的网站，其唯一目的是诱骗用户在这些网站中输入敏感信息。例如，如果您是一名哈佛学生，访问此类假哈佛网站，您可能会尝试登录并向对手提供您的用户名和密码</li>
<li><ul>
<li><em>跨站点脚本攻击</em> （ <em>XSS</em> ）是一种攻击形式，攻击者将代码附加到合法网站上, 通过用户的输入诱骗网站运行恶意代码。当受害者加载网站时，代码就会执行。</li>
</ul></li>
<li><em>反射攻击</em> 一种利用网站接受输入的方式来欺骗用户浏览器发送导致攻击的信息请求的攻击，如伪造了请求数据包的源 IP，接受请求的主机被诱骗将其 UDP 响应数据包发送到目标受害者 IP，而不是发送回攻击者的 IP 地址</li>
<li><em>存储攻击</em> 网站可能容易受到攻击，被诱骗存储恶意代码。</li>
<li><em>字符逃脱</em> 一些特殊字符如 <code>&lt;&gt;</code> 可用于注入恶意代码，对于特殊字符安全软件应该进行转义</li>
<li>常见的转义字符包括：
<ul>
<li><code>&amp;lt;</code>，“&lt;”</li>
<li><code>&amp;gt;</code>，“&gt;”</li>
<li><code>&amp;amp;</code>，“&amp;”</li>
<li><code>&amp;quot;</code>，“</li>
<li><code>&amp;apos;</code>，'</li>
</ul></li>
<li>可通过 html 标头仅允许通过单独的文件加载 js 或 css, 避免被注入标签执行恶意代码</li>
<li><em>SQL 注入</em> 利用 sql 语法注入代码并执行语句，类似字符逃脱，永远不要相信用户的输入，需要转义整个用户输入信息</li>
<li>现代常用的防止 sql 注入方法：预制 sql 模板，部分信息接收用户输入前必须转义输入</li>
<li>命令 <em>注入</em> 攻击是一种对底层系统本身发出命令的攻击。</li>
<li>如果命令从用户输入传递到命令行，效果可能是灾难性的。需要阅读编程语言系统接口的文档了解如何转义</li>
<li>不要相信 html 部分的验证，通过开发者工具可以随时更改，验证应该在服务端进行</li>
<li><em>跨站点请求伪造</em> / <em>CSRF</em> 诱骗用户在另一个网站上执行命令，如伪造一个亚马逊网站，用户点击网站购买的请求被攻击者转发给亚马逊，在此过程中攻击者可以得到受害人和亚马逊之间的所有收发数据</li>
<li>防止此类攻击的一种方法是使用 <em>CSRF 令牌</em> ，其中服务器为每个用户生成一个凭证令牌，令牌无法验证通过的请求是非法的</li>
<li>令牌通常通过 HTML 标头提交。</li>
<li><em>任意代码执行</em> （ <em>ACE</em> ）是执行不属于软件内预期代码的代码的行为。有时，此类攻击可用于 <em>破解</em> 或绕过注册或支付软件费用的需要或者逆向工程</li>
<li>应用程序商店采用加密技术，仅接受由授权开发人员签名的软件或代码。作为回应，应用程序商店使用数字签名对软件进行签名。因此，操作系统可以确保只安装经过授权、签名的软件。</li>
<li><em>包管理器</em> 采用类似的签名机制来确保您从第三方下载的内容是值得信赖的。但是，上游开源软件仍是有可能注入恶意代码的</li>
<li><em>common vulnerabilities and exposures</em> or <em>CVE</em> 是全球开发者可以查看的漏洞表，使其进行安全维护并确认安全优先级</li>
</ul>
<h2 id="隐私安全">隐私安全</h2>
<ul>
<li>浏览历史记录既是一种功能，也是对隐私的潜在威胁</li>
<li>服务器通常具有 <em>用户活动日志</em> 。因此，即使您清除浏览器历史记录，服务器也会跟踪您访问过的内容</li>
<li>当你通过 href 标签访问链接时，浏览器默认向跳转网站提供将您引向该网站的链接，也就是跳转到的网站的来源信息，包括您之前进行的搜索即搜索内容等来源</li>
<li>可以将以下元标记添加到您的网站，以限制仅发送来源域名或不提供来源信息。更多相关元标记可自行谷歌</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta name=&quot;referrer&quot; content=&quot;origin&quot;&gt; </span><br><span class="line">&lt;meta name=&quot;referrer&quot; content=&quot;none&quot;&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>每个浏览器都会提供有关您的身份和行为的信息，无论您选择哪种浏览器，服务器都会记录您的活动。</li>
<li><em>指纹识别</em> 是第三方可以根据可用线索识别您身份的一种方式，即使您已限制浏览器共享尽可能少的有关您的信息。</li>
<li>您的 IP 地址，屏幕分辨率、安装的扩展、安装的字体，常用语言，可以被逐渐收集，让您越来越容易被识别</li>
<li><em>Session cookie</em> 是服务器放置在您的计算机上用于识别您身份的信息，每个会话编号对于每个用户来说都是唯一的，通常有过期时间</li>
<li>第三方使用追踪 cookie 来跟踪您在网站上的行为，例如设定将这个 cookie 信息发给每个你访问的网站</li>
<li>url 中可以设置特殊参数来追踪用户, 如 <code>https://example.com/ad_engagement?click_id=YmVhODI1MmZmNGU4&amp;campaign_id=23</code> 中 <code>click_id</code> 用户追踪用户， 因此浏览器越来越倾向于清理跟踪参数</li>
<li>第三方（即其他服务器或公司）想要了解您如何在网站之间移动，例如在 a 网站的第三方广告设置一个 cookie, b 网站也有这个广告，发现你的 cookie，说明访问 ab 网站的事同一个用户</li>
<li>保护您的活动的一种方法是 <em>私密浏览</em> 。</li>
<li>在私人浏览窗口或选项卡中，过去的 cookie 将被删除。但新的 cookie 依旧可以生效</li>
<li>无论谁为您提供互联网服务，都可以在您不知情的情况下将他们自己的 cookie 注入到您的 HTTP 标头中</li>
<li><em>域名系统</em> DNS <em>是</em> 一种服务将域名转化为特定 ip 地址，按照惯例，到 DNS 的流量完全未加密。因此，您正在向全世界宣布您正在尝试访问哪个网站，您的互联网服务提供商和 DNS 服务确切地知道您尝试访问的位置</li>
<li><em>DNS over HTTPS</em> 或 <em>DoH</em> 以及 <em>DNS over TLS</em> 或 <em>DoT</em> 是您可以加密 DNS 请求的服务</li>
<li><em>Tor</em> 是一款将您的流量重定向到 Tor 服务器节点的软件。流量通过许多加密节点进行引导。根据设计，该软件不会记住您的大部分活动。使用此类服务​​很可能无法识别您的身份。</li>
<li>但请注意，如果您是工作地点或学校本地网络上唯一使用 Tor 的人，则很可能通过其他方式识别您的身份。</li>
<li><em>基于位置的服务</em> 提供您的地理位置。最好记住，如果您向 Apple 地图和 Google 地图提供此类权限，它们就非常清楚您在任何给定时间所在的位置</li>
<li>没有任何技术可以为您提供绝对的保护。</li>
</ul>
<h1 id="人工智能">人工智能</h1>
<p><a target="_blank" rel="noopener" href="https://cs50.harvard.edu/ai/2020">cs50</a></p>
<h2 id="搜索-search">搜索 search</h2>
<p>常见的搜索问题可由以下成分组成：</p>
<ul>
<li>问题状态</li>
<li>行动</li>
<li>代理人: 采取行动的实体</li>
<li>转换模型: 给出一对给定状态和行动产生的新状态</li>
<li>状态空间: 通过任何操作序列从初始状态可到达的所有状态的集合</li>
<li>目标测试: 判断是否已经达成目标</li>
<li>路径成本</li>
</ul>
<p>经典的搜索算法: dfs, bfs(略)</p>
<ul>
<li>非穷举情况下 dfs 无法保证最优解</li>
<li>bfs 保证最优解</li>
</ul>
<p>贪心最佳优先搜索:<br />
bfs 和 dfs 都是无信息算法，实际情况下，我们可以估计哪种搜索行动更优，例如曼哈顿距离(当前位置和目标在 x, y 轴距离的绝对值之和)更少的行动优先进行<br />
这种估算称为启发式函数，一般不保证最优</p>
<p>A star 算法:</p>
<ul>
<li>不仅考虑 <em>h(n)</em> （从当前位置到目标的估计成本），还考虑 <em>g(n)</em> （直到当前位置为止累积的成本）</li>
<li>如果估计成本 h(n) +g(n) 超过某个先前选项的估计成本，这条路径就会被放弃</li>
<li>为了使这种搜索最佳，需要:
<ul>
<li>估计成本小于等于真实成本</li>
<li>新节点到目标的估计路径成本+从前一个节点转移到该新节点的成本大于或等于前一个节点到目标的估计路径成本，即若 n'是 n 的后继节点且 c 是 n'到 n 的成本，<em>h(n) ≤ h(n’) + c</em> (确保在扩展新节点时, 不会选择比已有路径更差的路径)</li>
<li>根据以上条件，算法将优先向估计成本(实际成本上界)最小的方向逼近</li>
</ul></li>
</ul>
<h3 id="对抗性搜索-adversarial-search">对抗性搜索 Adversarial Search</h3>
<p>在这种搜索中算法面临着试图实现相反目标的对手。通常，在一些竞技游戏里会有对抗性 ai，例如井字棋</p>
<p><strong>极小极大</strong>: 将获胜条件表示为一侧 (-1) 和另一侧 (+1), 最小化一方试图获得最低分数，最大化一方试图获得最高分数</p>
<ul>
<li><em>S₀</em> ：初始状态（一个空的 3X3 板）</li>
<li><em>Players(s)</em> ：一个函数，给定状态 <em>s</em> ，返回轮到哪个玩家（X 或 O）</li>
<li><em>Actions(s)</em> ：一个函数，给定一个状态 <em>s</em> ，返回该状态下的所有合法动作（棋盘上哪些位置是空闲的）</li>
<li><em>Result(s, a)</em> ：一个函数，给定状态 <em>s</em> 和操作 <em>a</em> ，返回一个新状态。</li>
<li><em>Terminal(s)</em> ：一个函数，给定状态 <em>s</em> ，检查是否有人获胜或平局, 有则返回 True ， 否则返回 False</li>
<li><em>Utility(s)</em> : 一个函数, <em>给定最终状态 s</em> ，返回该状态的效用值：-1、0 或 1</li>
</ul>
<p>用伪代码表示，Minimax 算法的工作原理如下：</p>
<ul>
<li>给定一个状态 <em>s</em>
<ul>
<li>最大化玩家 : 在 <em>Actions(s)</em> 中选择产生 Min-Value(Result(s, a))值最高的动作 a</li>
<li>最小化玩家 : 在 <em>Actions(s)</em> 中选择产生 Max-Value(Result(s, a))值最低的动作 a</li>
</ul></li>
<li>Function <em>Max-Value(state)</em>
<ul>
<li><em>v = -∞</em></li>
<li>if <em>Terminal(state)</em>: ​ return <em>Utility(state)</em></li>
<li>for <em>action</em> in <em>Actions(state)</em>: ​ <em>v = Max(v, Min-Value(Result(state, action)))</em>; return <em>v</em></li>
</ul></li>
<li>Function <em>Min-Value(state)</em>:
<ul>
<li><em>v = ∞</em></li>
<li>if <em>Terminal(state)</em>: ​ return <em>Utility(state)</em></li>
<li>for <em>action</em> in <em>Actions(state)</em>: ​ <em>v = Min(v, Max-Value(Result(state, action)))</em> ; return <em>v</em></li>
</ul></li>
</ul>
<h4 id="alpha-beta-修剪-alpha-beta-pruning">Alpha-Beta 修剪 Alpha-Beta Pruning</h4>
<ul>
<li>Alpha 表示当前玩家(最大化玩家)可以确保获得的最小值</li>
<li>Beta 表示当前玩家的对手(最小化玩家)可以确保获得的最大值</li>
</ul>
<p>跳过一些明显不利的递归计算。在确定一个行动的价值后，如果有证据表明接下来的行动可以使对手获得比目前所知的最好行动使我方更差的行动机会，则无需进一步调查该行动，因为它肯定会不如先前的行动<br />
这说起很绕，其实可以这么理解，minimax 博弈假定双方都是理性者，并有全局视野，我们可以对手下一步的行动策略评估目前的行动(因为对手的策略必然是让我们赢面最小化), 因此我们可以多判断一步哪个选择后对手可以让我们赢面更低，然后丢弃这个选择<br />
例如下图中，23 选择看上去很好，但之后对手可以选一个更差的值，因此不如 1<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/0/alphabeta.png" /></p>
<h4 id="深度限制-depth-limited-minimax">深度限制 Depth-Limited Minimax</h4>
<p>设置一定的深度限制，到达限制就退出计算，并通过一个评估函数计算一名玩家相对于另一名玩家的有利程度</p>
<h2 id="知识-knowledge">知识 knowledge</h2>
<p>ai 使用逻辑来分析总结知识，关于世界的知识却体现在各种命题的真值中 命题 P→Q 表示若 P 必然有 Q，若非 P 对任何 Q 成立</p>
<table>
<thead>
<tr class="header">
<th>P</th>
<th>Q</th>
<th>P → Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>false</td>
<td>false</td>
<td>true</td>
</tr>
<tr class="even">
<td>false</td>
<td>true</td>
<td>true</td>
</tr>
<tr class="odd">
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>true</td>
<td>true</td>
<td>true</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>P</th>
<th>Q</th>
<th>P ↔︎ Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>false</td>
<td>false</td>
<td>true</td>
</tr>
<tr class="even">
<td>false</td>
<td>true</td>
<td>false</td>
</tr>
<tr class="odd">
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>true</td>
<td>true</td>
<td>true</td>
</tr>
</tbody>
</table>
<p>如果 α ⊨ β （α 蕴涵(Entailment) β），那么在任何 α 为真的世界中，β 也为真<br />
eg: 如果 α：“这是一月的星期二” 并且 β：“这是星期二”，那么 α ⊨ β<br />
与 → 不同的是：→ 表示命题之间的逻辑连接，与其连接的 PQ 组合成一个新的命题；⊨ 表示命题间的关系，在语义上可以表示为两个信息集合之间的关系</p>
<h3 id="推理-inference">推理 Inference</h3>
<p>最简单的推理方法莫过于穷举一个模型内所有条件的搭配,</p>
<p>如下图：</p>
<table>
<thead>
<tr class="header">
<th>P</th>
<th>Q</th>
<th>R</th>
<th>KB</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>false</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>false</td>
<td>false</td>
<td>true</td>
<td>false</td>
</tr>
<tr class="odd">
<td>false</td>
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>false</td>
<td>true</td>
<td>true</td>
<td>false</td>
</tr>
<tr class="odd">
<td>true</td>
<td>false</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>true</td>
<td>false</td>
<td>true</td>
<td>true</td>
</tr>
<tr class="odd">
<td>true</td>
<td>true</td>
<td>false</td>
<td>false</td>
</tr>
<tr class="even">
<td>true</td>
<td>true</td>
<td>true</td>
<td>false</td>
</tr>
</tbody>
</table>
<p>根据此表可确认 KB ⊨ R</p>
<p>对逻辑的代码表示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> logic <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new classes, each having a name, or a symbol, representing each proposition.</span></span><br><span class="line">rain = Symbol(<span class="string">&quot;rain&quot;</span>)  <span class="comment"># It is raining.</span></span><br><span class="line">hagrid = Symbol(<span class="string">&quot;hagrid&quot;</span>)  <span class="comment"># Harry visited Hagrid</span></span><br><span class="line">dumbledore = Symbol(<span class="string">&quot;dumbledore&quot;</span>)  <span class="comment"># Harry visited Dumbledore</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save sentences into the KB</span></span><br><span class="line">knowledge = And(  <span class="comment"># 以下每个命题真值为 True，因此由 And 开始</span></span><br><span class="line">    Implication(Not(rain), hagrid),  <span class="comment"># ¬(It is raining) → (Harry visited Hagrid)</span></span><br><span class="line">    Or(hagrid, dumbledore),  <span class="comment"># (Harry visited Hagrid) ∨ (Harry visited Dumbledore).</span></span><br><span class="line">    Not(And(hagrid, dumbledore)),  <span class="comment"># ¬(Harry visited Hagrid ∧ Harry visited Dumbledore) i.e. Harry did not visit both Hagrid and Dumbledore.</span></span><br><span class="line">    dumbledore  <span class="comment"># Harry visited Dumbledore. Note that while previous propositions contained multiple symbols with connectors, this is a proposition consisting of one symbol. This means that we take as a fact that, in this KB, Harry visited Dumbledore.</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_all</span>(<span class="params">knowledge, query, symbols, model</span>):</span><br><span class="line">    <span class="comment"># If model has an assignment for each symbol</span></span><br><span class="line">    <span class="comment"># (The logic below might be a little confusing: we start with a list of symbols. The function is recursive, and every time it calls itself it pops one symbol from the symbols list and generates models from it. Thus, when the symbols list is empty, we know that we finished generating models with every possible truth assignment of symbols.)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> symbols:</span><br><span class="line">        <span class="comment"># If knowledge base is true in model, then query must also be true</span></span><br><span class="line">        <span class="keyword">if</span> knowledge.evaluate(model):</span><br><span class="line">            <span class="keyword">return</span> query.evaluate(model)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Choose one of the remaining unused symbols</span></span><br><span class="line">        remaining = symbols.copy()</span><br><span class="line">        p = remaining.pop()</span><br><span class="line">        <span class="comment"># Create a model where the symbol is true</span></span><br><span class="line">        model_true = model.copy()</span><br><span class="line">        model_true[p] = <span class="literal">True</span></span><br><span class="line">        <span class="comment"># Create a model where the symbol is false</span></span><br><span class="line">        model_false = model.copy()</span><br><span class="line">        model_false[p] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p><code>check_all</code> 函数是递归的。也就是说，它选择一个符号，创建两个模型，其中一个该符号为真，另一个该符号为假，然后再次调用自身，现在有两个模型，两者真值分配不同。循环直到模型中的所有符号都被分配了真值即 <code>symbols</code> 为空</p>
<h3 id="知识工程-knowledge-engineering">知识工程 Knowledge Engineering</h3>
<p>知识工程是关于如何在人工智能中表示命题逻辑 Propositional Logic 的过程<br />
假设我们有三个人：Mustard、Plum 和 Scarlet，三种工具：小刀、左轮手枪和扳手，以及三个地点：舞厅、厨房和图书馆，需要推理 when who how 三个问题<br />
游戏一开始，每个玩家都会看到一个人、一件工具和一个地点，从而知道他们与谋杀案无关。玩家不会分享在这些卡片中看到的信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add the clues to the KB</span></span><br><span class="line">knowledge = And(</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start with the game conditions: one item in each of the three categories has to be true.</span></span><br><span class="line">    Or(mustard, plum, scarlet),</span><br><span class="line">    Or(ballroom, kitchen, library),</span><br><span class="line">    Or(knife, revolver, wrench),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add the information from the three initial cards we saw</span></span><br><span class="line">    Not(mustard),</span><br><span class="line">    Not(kitchen),</span><br><span class="line">    Not(revolver),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一个猜测如果错误可以表示为以下形式</span></span><br><span class="line">    Or(Not(scarlet), Not(library), Not(wrench)),</span><br><span class="line"></span><br><span class="line">    <span class="comment">#假设别人向我们出示他们的信息:</span></span><br><span class="line">    Not(plum),</span><br><span class="line">    Not(ballroom)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>考虑以下示例：四个不同的人，吉德罗、波莫娜、密涅瓦和霍勒斯，被分配到四个不同的学院：格兰芬多、赫奇帕奇、拉文克劳和斯莱特林。每栋房子里只有一个人<br />
假设使用命题逻辑，我们将编写:<br />
(密涅瓦·格兰芬多 → ¬ 米勒娃·赫奇帕奇) ∧ (密涅瓦·格兰芬多 → ¬ 米勒娃·拉文克劳) ∧ (密涅瓦·格兰芬多 → ¬ 米勒娃·斯莱特林) ∧ (密涅瓦·赫奇帕奇 → ¬ 米勒娃·格兰芬多)…</p>
<div class="note info"><p>面对较为复杂的问题，一阶逻辑是另一种类型的逻辑，可以让我们比命题逻辑更简洁地表达更复杂的想法, 使用两种类型的符号： <em>常量符号</em> 和 <em>谓词符号</em> Constant Symbols and Predicate Symbols 我们可以使用 Person(Minerva) 句子来表达 Minerva 是一个人的命题。类似地，我们可以使用句子 House(Gryffindor) 来表达格兰芬多是一所房子的命题<br />
谓词符号还可以采用两个或多个参数并表达它们之间的关系。例如，BelongsTo 表达两个参数（人和该人所属的房屋）之间的关系, 米勒娃属于格兰芬多的想法可以表达为 BelongsTo(米勒娃，格兰芬多)<br />
量化是一种可以在一阶逻辑中使用来表示句子的工具，而无需使用特定的常量符号。通用量化使用符号 ∀ 来表达“对于所有人”<br />
存在量化用于创建对至少一个 x 成立的句子。用符号 ∃ 表示<br />
存在量化 Existential Quantification 和全称量化 Universal Quantification 可以在同一句话中使用。例如，句子 <code>∀x。 Person(x) → (∃y.House(y) ∧ BelongsTo(x, y))</code> 表达了这样的想法：如果 x 是一个人，则至少有一个房子 y 是这个人所属的。换句话说，这句话的意思是每个人都至少属于一所房子</p>
</div>
<p><strong>Mastermind 游戏</strong><br />
在这个游戏中，玩家一按照一定的顺序排列颜色，然后玩家二必须猜测这个顺序。每回合，玩家二进行猜测，玩家一给出一个数字，表明玩家二猜对了多少种颜色，假设有四个颜色需要猜测</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/mastermind3.png" /></p>
<p>用命题 red0、red1、red2、red3、blue0… 代表颜色和位置，用命题逻辑表示游戏规则（每个位置只有一种颜色并且没有颜色重复）并将它们添加到知识库中，随后不断补充线索，随后模型检查算法可以为我们提供难题的解决方案</p>
<h3 id="推理规则-inference-rules">推理规则 Inference Rules</h3>
<p>模型检查不是一种高效的算法，因为它必须在给出答案之前考虑每个可能的模型<br />
推理规则使我们能够根据现有知识生成新信息，而无需考虑每种可能的模型<br />
假设：</p>
<ul>
<li>如果下雨，那么哈利在屋子里</li>
<li>正在下雨</li>
</ul>
<p>基于此，理性的人都可以得出这样的结论：</p>
<ul>
<li>哈利在屋里</li>
</ul>
<p>一些基本的推理规则: <img src="https://cs50.harvard.edu/ai/2020/notes/1/modusponens.png" /></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/implicationelimination.png" /></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/demorgans1.png" /></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/demorgans2.png" /></p>
<p>具有用 And 或 Or 连接词分组的两个元素的命题可以分解为由 And 和 Or 组成的更小的单元</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/distributive1.png" /></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/1/distributive2.png" /></p>
<p>推理可以被视为具有以下属性的搜索问题：</p>
<ul>
<li>初始状态：启动知识库</li>
<li>动作：推理规则</li>
<li>转换模型：推理后的新知识库</li>
<li>目标测试：检查我们要证明的语句是否在知识库中</li>
<li>路径成本函数：证明中的步骤数</li>
</ul>
<p>析取 <strong>disjunction</strong> 由与 Or 逻辑连接词连接的命题组成, 子句 <strong>clause</strong> 是对文字 literals (命题符号或命题符号的否定)的析取, 如 (P ∨ Q ∨ ¬R)<br />
由 And 逻辑连接词 (P ∧ Q ∧ R) 连接的子句允许我们将任何逻辑语句转换为 <strong>合取范式</strong> （CNF Conjunctive Normal Form），即子句的合取，例如：(A ∨ B ∨ C) ∧ (D ∨ ¬E) ∧ (F ∨ G)<br />
求合取范式的过程:</p>
<ul>
<li>消除双条件句
<ul>
<li>Turn (α ↔︎ β) into (α → β) ∧ (β → α).</li>
</ul></li>
<li>消除条件句
<ul>
<li>Turn (α → β) into ¬α ∨ β.</li>
</ul></li>
<li>使用德摩根定律，将否定向内移动
<ul>
<li>Turn ¬(α ∧ β) into ¬α ∨ ¬β</li>
</ul></li>
</ul>
<p>将 (P ∨ Q) → R 转换为合取范式的示例：</p>
<ul>
<li>(P ∨ Q) → R</li>
<li>¬(P ∨ Q) ∨ R</li>
<li>(¬P ∧ ¬Q) ∨ R</li>
<li>(¬P ∨ R) ∧ (¬Q ∨ R)</li>
</ul>
<p>得到的合取范式可以继续简化，如(P ∨ Q ∨ S) ∧ (¬P ∨ R ∨ S) 可化为 (Q ∨ R ∨ S)</p>
<p>要确定 KB ⊨ α 是否为真：</p>
<ul>
<li>检查：(KB ∧ ¬α) 是否矛盾？
<ul>
<li>如果是这样，则 KB ⊨ α</li>
<li>否则，无蕴涵关系</li>
</ul></li>
</ul>
<p>就计算机算法而言，可使用以下步骤:</p>
<ul>
<li>将 (KB ∧ ¬α) 转换为合取范式</li>
<li>检查是否可以生成新的子句</li>
<li>如果产生空子句（相当于 False），那么得出矛盾，从而证明了 KB ⊨ α</li>
<li>然而，如果没有矛盾并且不能推断出更多的子句，则不存在蕴涵</li>
</ul>
<p>示例:(A ∨ B) ∧ (¬B ∨ C) ∧ (¬C) 是否蕴含 A？</p>
<ul>
<li>首先，为了反证，我们假设 A 是假的。因此，我们得到 (A ∨ B) ∧ (¬B ∨ C) ∧ (¬C) ∧ (¬A)</li>
<li>现在，我们可以开始生成新信息。因为我们知道 C 是假的 (¬C)，所以 (¬B ∨ C) 为真的唯一方法是 B 也为假。因此，我们可以将 (¬B) 添加到我们的知识库中</li>
<li>接下来，由于知道 (¬B)，所以 (A ∨ B) 为真的唯一方法是 A 为真。因此可以将 (A) 添加到知识库中</li>
<li>现在我们的知识库有两个互补的文字：(A) 和 (¬A)。抵消得到空集（）。根据定义，空集是假的，因此遇到了矛盾</li>
</ul>
<h2 id="概率-uncertainty">概率 Uncertainty</h2>
<p><code>0 &lt;p（ ω ）&lt;1</code>：代表概率的值必须在 0 到 1 之间。零是不可能的事件, 如扔 1-6 的骰子扔出 7。<br />
<code>p(a|b)</code> 表示给定 b 条件下 a 的概率<br />
可以用向量表示一系列事件的概率，如 <code>P(Flight) = &lt;0.6, 0.3, 0.1&gt;  (准时，延误，取消)</code></p>
<p>概率规则：</p>
<ul>
<li>P(¬a) = 1 - P(a)</li>
<li>P(a ∨ b) = P(a) + P(b) - P(a ∧ b)</li>
<li>P(a) = P(a, b) + P(a, ¬b)</li>
<li>独立性: P(a ∧ b) = P(a)P(b)<br />
</li>
<li>贝叶斯: P(a|b) = P(a ∧ b)P(b) 其中: P(a ∧ b)= p(a|b)p(b)</li>
</ul>
<p>联合概率 Joint Probability：多个事件同时发生的概率</p>
<table>
<thead>
<tr class="header">
<th>C = <em>cloud</em></th>
<th>C = <em>¬cloud</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.4</td>
<td>0.6</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>R = <em>rain</em></th>
<th>R = <em>¬rain</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.1</td>
<td>0.9</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>R = <em>rain</em></th>
<th>R = <em>¬rain</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C = <em>cloud</em></td>
<td>0.08</td>
<td>0.32</td>
</tr>
<tr class="even">
<td>C = <em>¬cloud</em></td>
<td>0.02</td>
<td>0.58</td>
</tr>
</tbody>
</table>
<p>联立不同条件的情况下， P(C, rain) = P(C ∧ rain)，P(C | rain) = P(C ∧ rain)/P(rain)<br />
此时，可写作 P(C, rain)/P(rain) = αP(C, rain), 或 α &lt;0.08, 0.02&gt; ，即规定 rain 的情况下 c 的分布，我们知道 c 的所有分布和为 1，因此需要一个 α 系数将其化 1</p>
<p>贝叶斯网络:</p>
<ul>
<li>用定向图表示</li>
<li>图上的每个节点代表一个随机变量</li>
<li>从 x 到 y 的箭头表示 x 是 y 的父节点。也就是说，y 的概率分布取决于 x 的值</li>
<li>每个节点 X 具有概率分布 P(X | Parents(X))</li>
</ul>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/2/bayesiannetwork.png" /></p>
<p>例如，如果想得到 P(小雨, 不维护，列车推迟，错过会议)，就可以通过 P(light)P(no | light)P(delayed | light, no)P(miss | delayed)得到<br />
实际情况中，部分变量可能难以观察到</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/2/inferencebyenumeration.png" /> 如图，X 是被观察的变量，e 是可见的证据，y 则是隐藏变量的所有可能取值，α 归一化结果，使最终得到的概率总计为 1<br />
例如 P(Appointment, light, no) = α [P(Appointment, light, no, delayed) + P(Appointment, light, no, on time)]<br />
因此，在不知道 y 的分布情况下也可以根据 e 进行分布推断</p>
<h3 id="采样-sampling">采样 Sampling</h3>
<p>通过对一个变量多次采样，可以估算其概率分布，如果想得到例如 p(a|b)的概率，可以简单地用 p(a)/p(b)估算，对非 b 条件的情况可以直接忽略<br />
也可以计算基于附加变量的概率分布，固定证据变量 a，使用贝叶斯网络中的条件概率对非证据变量加权，例如，例如 a 是列车准时(直接赋予 on time 这个值)，对所有样本按贝叶斯网络加权，如小雨且维护的样本需要加权 P(Train = on time | light, yes)</p>
<h3 id="马尔可夫模型-markov-models">马尔可夫模型 Markov Models</h3>
<p>马尔可夫假设： 当前状态只取决于以前有限个且固定个的状态<br />
马尔可夫链是一个随机变量的序列，其中每个变量的分布遵循马尔可夫假设。也就是说，链中的每个事件都基于之前事件发生的概率</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/2/transitionmodel.png" /></p>
<p>隐马尔可夫模型 Hidden Markov Model：现实世界有很多无法被观察的变量影响发生的事件，在这些情况下，世界状态称为隐藏状态 ，而 AI 可以访问的数据是观察结果，基于这个假设的马儿可夫模型<br />
例如：</p>
<ul>
<li>对于探索未知地形的机器人，隐藏的状态是其位置，观察对象是机器人传感器记录的数据。</li>
<li>在语音识别中，隐藏状态是所说的单词，观察对象是音频波形。</li>
<li>评估用户在网站上的参与度时，隐藏的状态是用户的参与度，并且观察对象是网站或应用存储的数据。</li>
</ul>
<p>传感器马尔可夫假设 Sensor Markov assumption：证据变量仅取决于相应状态的假设。例如，上方例子假设人们是否将雨伞带到办公室仅取决于天气，人们可能的其他特点(例如皮肤不好不能晒太阳)则是隐藏状态，并不被纳入考虑 假设 ai 想观测天气，但传感器只有一个监控器可以判断人们有没有带伞, 通过观察人们是否带来了雨伞，可以合理猜测外面的天气 <img src="https://cs50.harvard.edu/ai/2020/notes/2/sensormodel.png" /></p>
<p>通过对证据变量的记录和学习，可以推测过去，现在，未来的隐藏变量状态</p>
<h2 id="优化-optimization">优化 Optimization</h2>
<p>优化是从一组可能的选项中选择最佳选项。<br />
例如曼哈顿距离就是计算当前位置与目标点 xy 坐标差的绝对值之和来估计成本，而 a star 算法通过这种估计来优先选择下一个可能路径</p>
<p>本地搜索 Local Search 是一种搜索算法，它通过维护当前节点的属性，然后移动到相邻节点，重复直到搜索到一个满意的状态。例如给定一些房屋位置，要为新建的医院选址，让距离和最短</p>
<p>爬山 Hill Climbing 算法 ：一种本地搜索，给定当前状态，寻找一个最佳邻居状态，若这个邻居比当前更优，转移到邻居，如此循环。最后会到达一个极值<br />
问题在于，极值未必是最大值，且如果两个邻居和当前一样，算法什么都不会做<br />
改进：以随机初始状态重复几次，或者每次可以选 k 个邻居进行比较(k &gt;= 2)</p>
<p>退火是使被加热的金属缓慢冷却的过程，这可以使金属变硬。模拟退火 Simulated Annealing 算法指的是：从高温开始，更有可能做出随机决策，并且随着温度降低，越来越不可能做出随机决策<br />
算法有一个 max 参数规定最多可以比较的次数，t 函数每次返回一个温度值，温度初期较高，逐渐降低，ΔE 表示目前和邻居状态的差值，大于 0 是直接移到邻居位置，否则以 e^(ΔE/T)的概率移动。即温度和状态差同时影响移动概率</p>
<p>线性编程 Linear Programming ：给定若干元 x1-xn, 以及成本系数 a1-an, 元之间的若干约束，计算最低成本的取值，对其的优化可以使用 Simplex 算法和 Interior-Point 算法(牛顿迭代)</p>
<h3 id="约束满足-constraint-satisfaction">约束满足 Constraint Satisfaction</h3>
<p>约束满意度问题：在满足某些条件的同时分配变量 例如：学生学习的课程有 A，B，…，G 都是变量。每个课程都需要考试，考试的可能日子是星期一，星期二和星期三，也就是变量的域。但是，同一学生不能在同一天进行两次考试。在这种情况下，变量是课程，域是日子，而限制是不能安排在同一天进行考试的限制因素<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/3/constraintsatisfaction1.png" /></p>
<p>图上的每个节点都是一门课程，如有两门课不能安排在同一天，就添加一条弧<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/3/constraintsatisfaction2.png" /></p>
<ul>
<li>硬约束：在正确解决方案中必须满足的约束。</li>
<li>软约束：表示解决方案的优劣性</li>
<li>单元约束：仅涉及一个变量的约束。如课程在星期一不能进行考试{ a≠ 星期一 }。</li>
<li>二元约束: 涉及两个变量的约束。如两个课程不能具有相同的值{ a≠b }。</li>
</ul>
<p>节点的一致性(Node Consistency): 某个变量在变量域中所有取值都可以满足对该变量的一元约束，例如对变量课程 a, b 来说，其域是星期一二三，{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}，此时 ab 都没有变量一致性，因为 ab 的取值都定死了，如果移除 A ≠ Mon, a 就会有一致性，如果要让 b 也有一致性，就需要移除周二周三两个约束</p>
<p>弧的一致性(Arc Consistency): 某个变量在变量域中所有取值都可以满足对该变量二元约束，即对每个 a 至少有一个 b 取值满足 ab 间约束关系，类似节点一致性，在上个例子中，如果 a 取周三，b 将无法取值，因此需要移除 a!= b 约束，移除后 a 就有了弧一致性<br />
以下算法通过移除 x 无法满足二元约束的取值来保证 x 的弧一致性(最坏情况下会删掉 x 所有的取值范围)，换句话说就是找到二元约束下 x 能取的值:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">function Revise(csp, X, Y):<span class="comment">#CSP 代表“约束满意度问题”</span></span><br><span class="line">    revised = false<span class="comment">#表示是否有更改 x 的域</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> X.domain:</span><br><span class="line">        <span class="keyword">if</span> no y <span class="keyword">in</span> Y.domain satisfies constraint <span class="keyword">for</span> (X,Y):</span><br><span class="line">            delete x <span class="keyword">from</span> X.domain</span><br><span class="line">            revised = true</span><br><span class="line">    <span class="keyword">return</span> revised</span><br></pre></td></tr></table></figure>
<p>一般来说，我们会希望能让每个变量都有弧一致性，因此需要使用 ac-3 算法</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">function AC-<span class="number">3</span>(csp):</span><br><span class="line">    queue = <span class="built_in">all</span> arcs <span class="keyword">in</span> csp</span><br><span class="line">    <span class="keyword">while</span> queue non-empty:</span><br><span class="line">        (X, Y) = Dequeue(queue)</span><br><span class="line">        <span class="keyword">if</span> Revise(csp, X, Y):</span><br><span class="line">            <span class="keyword">if</span> size of X.domain == <span class="number">0</span>:<span class="comment">#此时失败，给定约束下 x 无法取任何值</span></span><br><span class="line">                <span class="keyword">return</span> false</span><br><span class="line">            <span class="keyword">for</span> each Z <span class="keyword">in</span> X.neighbors - &#123;Y&#125;:<span class="comment">#修改后需要查看与 X 相关的所有弧线是否仍然一致。</span></span><br><span class="line">                Enqueue(queue, (Z,X))</span><br><span class="line">    <span class="keyword">return</span> true</span><br></pre></td></tr></table></figure>
<p>弧一致性的算法可以简化问题，但不一定会解决问题，因为它仅考虑二元约束，而不是如何互连多个节点。</p>
<p>约束满意度问题可以看作是一个搜索问题：</p>
<ul>
<li>初始状态：空任务（所有变量都没有分配给它们的任何值）。</li>
<li>操作：向分配添加{ variable = value }; 也就是说，给一些变量一个值。</li>
<li>过渡模型：显示添加分配的方式如何改变整个任务。返回包括最新动作之后的状态。</li>
<li>目标测试：检查是否可以分配所有变量，并满足所有约束。</li>
<li>路径成本：所有路径的成本相同。正如我们前面提到的，与典型的搜索问题相反，优化问题关心解决方案，而不是通往解决方案的途径。</li>
</ul>
<h3 id="回溯搜索-backtracking-search">回溯搜索 Backtracking Search</h3>
<p>用于解决约束满意度问题的递归搜索算法，如果满足约束，继续分配值，否则尝试不同的任务</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> assignment complete:</span><br><span class="line">    <span class="keyword">return</span> assignment</span><br><span class="line"></span><br><span class="line">var = Select-Unassigned-Var(assignment, csp)</span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> Domain-Values(var, assignment, csp):</span><br><span class="line">    <span class="keyword">if</span> value consistent <span class="keyword">with</span> assignment:</span><br><span class="line">        add &#123;var = value&#125; to assignment</span><br><span class="line">        result = Backtrack(assignment, csp)</span><br><span class="line">        <span class="keyword">if</span> result ≠ failure:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        remove &#123;var = value&#125; <span class="keyword">from</span> assignment</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> failure</span><br></pre></td></tr></table></figure>
<p>流程:</p>
<ol type="1">
<li>假设任务完成(变量分配完)，直接返回</li>
<li>选择一个未分配变量，遍历变量的所有取值
<ol type="1">
<li>如果有一个取值不和之前的约束矛盾, 添加这个取值进当前状态进入递归</li>
<li>递归返回后，如果其中的子问题有解，返回结果</li>
<li>运行到这步说明这种取值不行，那么移除该取值</li>
</ol></li>
<li>运行到这里说明所有尝试都失败了，返回失败信息，这说明需要回溯到之前的某个状态，当前是无解的</li>
</ol>
<p>作为简单粗暴的递归算法，回溯搜索的复杂度很高，考虑到维持弧一致性的成本相对较低，我们可以考虑把 ac-3 算法融合进来，这个算法称为 Maintaining Arc-Consistency algorithm，会在每次新的赋值后维持弧一致性</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">function Backtrack(assignment, csp):</span><br><span class="line">    <span class="keyword">if</span> assignment complete:</span><br><span class="line">        <span class="keyword">return</span> assignment</span><br><span class="line">    var = Select-Unassigned-Var(assignment, csp)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> Domain-Values(var, assignment, csp):</span><br><span class="line">        <span class="keyword">if</span> value consistent <span class="keyword">with</span> assignment:</span><br><span class="line">            add &#123;var = value&#125; to assignment</span><br><span class="line">            inferences = Inference(assignment, csp)</span><br><span class="line">            <span class="keyword">if</span> inferences ≠ failure:</span><br><span class="line">                add inferences to assignment</span><br><span class="line">            result = Backtrack(assignment, csp)</span><br><span class="line">            <span class="keyword">if</span> result ≠ failure:</span><br><span class="line">                <span class="keyword">return</span> result</span><br><span class="line">            remove &#123;var = value&#125; <span class="keyword">and</span> inferences <span class="keyword">from</span> assignment</span><br><span class="line">    <span class="keyword">return</span> failure</span><br></pre></td></tr></table></figure>
<p>优化: 与随机选择一个新变量相比，我们可以用一些经(玄)验(学)法则，说不定有更好的效果, 也就是所谓的启发式 heuristic</p>
<ul>
<li>Minimum Remaining Values (最少剩余值 MRV) ，优先选择取值范围最少的变量，这是个很符合直觉的想法，如果这条路会失败，那我们应该尽早排除它，此外，这么一来可以尽可能多地约束其他变量的度数。而当变量的取值范围相同时，自然的想法就是选度数最高的变量赋值<br />
</li>
<li>当我们从变量的域中选择一个值时，使算法更有效的另一种方法是采用另一种启发式 Least Constraining Values(最少限制值) , 选一个能约束最少其他变量的变量值，也就是说，我们想定位最大的麻烦来源（最高度数的变量），然后使其成为最不麻烦的问题（为其分配最小约束值）</li>
</ul>
<h2 id="机器学习-machine-learning">机器学习 Machine Learning</h2>
<p>最大的概念，为计算机提供数据，通过学习这些数据让计算机学会识别模式并执行任务</p>
<h3 id="监督学习-supervised-learning">监督学习 Supervised Learning</h3>
<p>计算机基于一个函数对数据集进行输入映射到输出的任务，监督学习有多个任务，其中之一是分类，即用函数将输入映射到离散输出的任务<br />
例如输入温度，湿度和气压，输出下雨或者不下雨。<br />
如下图红色代表不下雨，蓝色表示下雨，白色需要映射:<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/4/nearestneighbor.png" /></p>
<p>最简单的策略莫过于直接选一个最近点作为输出，即 Nearest-Neighbor Classification，但如上图可能出现不准确问题，对其的改进可以是 k-邻近算法，选 k 个最近点的最多输出作为输出<br />
缺点在于计算距离开销较大</p>
<p>常用的库是 scikit-learn, 常叫 sklearn</p>
<h4 id="感知机学习-perceptron-learning">感知机学习 Perceptron Learning</h4>
<p>简单地说就是画出一条分界线，用来分类或者决策，说起来简单，实际上很难选出最好的分界线<br />
在这个例子里，判断数据在边界哪侧只需要用一个线性方程，属于初中数学范畴，不多赘述<br />
<span class="math inline">\(\ {h}_{\mathrm{W}}({\bf x})={\begin{array}{l}{1\,\mathrm{if}\;{ W}\ {\cdot\;{\bf X}}\geq0}\\ {0\,\mathrm{otherwise}}\end{array}}\,\)</span></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/4/decisionboundary.png" /><br />
感知机的重点是，找到最好的权重，其学习规则是:<br />
<span class="math inline">\(w_{i}=w_{i}+α(y-h_{w}({\bf x}))\times x_{1}\)</span><br />
对于每个数据点，我们调整权重以使函数更加准确，y 表示观察到的值，h(假设函数)表示估计值，如果观察下雨但估计没下，括号里的参数设 1，相反的情况下设-1，α 则表示新数据对总体权值的影响力<br />
这种离散输出模型的缺点是，无法表示不确定性，可以将其平滑化，使用软阈值，最后输出一个估计概率</p>
<h4 id="支持向量机-support-vector-machines">支持向量机 Support Vector Machines</h4>
<p>该方法在决策边界附近使用额外的向量（支持向量），以在分离数据时做出最佳决策。 <img src="https://cs50.harvard.edu/ai/2020/notes/4/supportvector.png" /> <img src="https://cs50.harvard.edu/ai/2020/notes/4/circleboundary.png" /><br />
例如, 直觉来说最好的划分应该离两个每个组有相同的距离，即边界离其所分离的两组尽可能远，这被称为最大边缘分离器 Maximum Margin Separator<br />
以及，支持向量机可以在复数维度上创建分界线</p>
<h4 id="回归-regression">回归 Regression</h4>
<p>回归是一项函数的监督学习任务，该任务将输入点映射到连续值 <img src="https://cs50.harvard.edu/ai/2020/notes/4/regression.png" /> 最经典的线性回归在线代课里讲过，简单地说就是找到距离平方和最小的直线来拟合输出<br />
给定一组输入特征 X = [x1, x2, ..., xn] 和相应的目标输出 y。<br />
目标是找到一个线性函数 h(X) = θ0 + θ1 <em>x1 + θ2</em> x2 + ... + θn*xn 来拟合数据。<br />
其他比较常见的回归有随机森林，决策树等</p>
<h4 id="损失函数-loss-functions">损失函数 Loss Functions</h4>
<p>损失函数用于评估以上决策规则的准确度 对分类问题，可以简单地用 01 二分法；而连续值可以用 l₁ 和 l₂ 损失函数，前者为线性差值的绝对值，在坐标轴上就是 y 轴上的距离，后者为差值平方，很明显，l2 更为严格</p>
<h4 id="过拟合-overfitting">过拟合 Overfitting</h4>
<p>模型过于适配训练数据集以至于无法推广其他训练集<br />
测试过拟合的常用方法是 <strong>交叉验证 Cross Validation</strong>, 如最简单的 holdout 交叉验证，只分一次训练和验证集；而 k 折交叉验证就是将训练集分为 k 份，每次选一份用于验证，其他 k-1 份用于训练, 这样一共能验证 k 次<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/4/overfitting.png" /></p>
<h4 id="正则化-regularization">正则化 Regularization</h4>
<p>正则化在损失函数中加入一个惩罚项, 降低模型复杂度, 限制模型参数的大小或数量, 从而防止过拟合, 提高模型的泛化能力。<br />
cost(h) = loss(h) + λcomplexity(h)<br />
lambda（λ）是一个常数，我们可以用它来调节对我们成本功能的复杂性的惩罚程度。 λ 越高，复杂性的惩罚越强<br />
常用 l1(Lasso 回归), l2(Ridge 回归) 正则化，即复杂度用权重矩阵绝对值和或平方和表示<br />
一般来说 l1 适合让参数稀疏化(部分权值会被降到 0)，适合特征选择；l2 相对会惩罚高权重从而更能防止过拟合(但不会降到 0)</p>
<h3 id="强化学习-reinforcement-learning">强化学习 Reinforcement Learning</h3>
<p>强化学习是一种用于机器学习的方法，在每个动作之后，代理以奖励或惩罚的形式（正值或负值）获得反馈。 <img src="https://cs50.harvard.edu/ai/2020/notes/4/reinforcement.png" /> 环境为代理提供初始状态，代理根据状态执行行动并不断获得反馈<br />
这种类型的算法可用于训练步行机器人，例如成功走了一步是正反馈，摔倒是负反馈</p>
<h4 id="马尔可夫决策过程-markov-decision-processes">马尔可夫决策过程 Markov Decision Processes</h4>
<p>强化学习可以看作是马尔可夫决策过程，具有以下属性：</p>
<ul>
<li>Set of states S</li>
<li>Set of actions Actions(S)</li>
<li>Transition model P(s’ | s, a)</li>
<li>Reward function R(s, a, s’)</li>
</ul>
<p>在每个时间步骤中，随机过程都处于某种状态 s，决策者可以选择在状态 s 下可用的动作 a。该随机过程在下一时间步骤会随机进入新状态 s′，并给予决策者相应的回馈 Ra(s, s′)<br />
随机过程进入新状态 s′的概率受所选操作影响。具体来说，它是由状态变换函数 P 给出的。因此，下一个状态 s′取决于当前状态 s 和决策者的动作 a。给定 s 和 a，它条件独立于所有先前的状态和动作<br />
马尔可夫决策过程是马尔可夫链的推广，不同之处在于添加了行动(选择)和奖励（反馈）。</p>
<p>如图，代理是黄色圆圈，它需要到达绿色正方形的同时避开红色正方形。上下左右移动是动作，过渡模型在动作后产生新状态，并且代理会获得反馈<br />
图中代理如果想向右移动，会得到一个负面反馈；到达绿色方形时会得到正面反馈<br />
<img src="https://cs50.harvard.edu/ai/2024/notes/4/markov.png" /></p>
<h4 id="q-学习-q-learning">Q 学习 Q-Learning</h4>
<p>一种强化学习模型，使用的函数 Q 函数 <strong><em>Q(s, a)</em></strong> 接收 s 状态下的行动 a，并产生对其的一个评估值，注意这个评估值和回馈 r 不同<br />
起初，所有 q 函数的输出为 0，随着模型不断“行动-反馈”的过程，模型不断基于当前状态给出输出，以及不断考虑过往估计与新估计，并以此更新函数规则。即在过程中就可以不断总结经验自我学习。<br />
<strong><em>Q(s, a) ⟵ Q(s, a) + α(new value estimate - Q(s, a))</em></strong><br />
α 表示调整的权重</p>
<p>那么新的估计怎么产生呢? 可以表述为当前收到的回馈 r 以及估计的未来回馈的(加权)和；模型会记录之前的(状态，回馈)表，估计的未来回馈用最近一次行动后的最新状态，在这个状态下根据过往经验选一个最高回馈，即记录表中 Q(s', a')里的最高值。对未来回馈的估计也可以用一个系数 γ 约束，公式如下:<br />
<span class="math inline">\(Q(s,a)\leftarrow Q(s,a)+\alpha((r+\gamma\,\mathrm{max}_{\mathrm{a&#39;}}\!\cdot\!\mathrm{Q}(s^{\prime},\,{\mathrm{a}}^{\prime}))-\mathrm{Q}(s,a))\)</span><br />
例如对某个(s, a)对, 其 r 值直接查表得到，这个 a 后得到一个新状态 s'，查表 s'状态下最好的 r，我们假设之后的新行为 a'能得到这个最好的 r，因此以此来更新 Q 函数</p>
<p>贪婪决策算法 <strong>Greedy Decision-Making</strong> 总是选取估计回馈最好的行动，而不是根据状态选出 Q(s, a)最好的行动，这往往能解决问题，但并非全局最优<br />
总的来说，这可以归类于 <strong>Explore vs. Exploit</strong> tradeoff，是一个经典的问题。为了避免 exploit 带来的问题，例如限于以往经验不走了，可以对贪心进行改进，以一个概率 ε 决定是否贪心当前最优解，还是选一个随机解，称为 (epsilon) greedy algorithm</p>
<p>训练强化学习模型的另一种方法是，在整个任务完成后才给予评估，而不是每一步。对一些博弈游戏，这样的训练方式可能更有效。<br />
对状态集和动作相对复杂的作业，如国际象棋来说，很难对每个动作进行估计，需要进行函数近似 <strong>function approximation</strong>，将类似的状态行动队归到一起用于产生估计值</p>
<h3 id="无监督学习-unsupervised-learning">无监督学习 Unsupervised Learning</h3>
<p>在无监督的学习中，仅存在输入数据，并且 AI 在这些数据中学习模式，不需要特定输出输出<br />
例如聚类是一项无监督的学习任务，它将输入数据获取并将其组织为不同的组，使类似对象被分入同一组。被用于遗传学之类的领域</p>
<h4 id="k-均值聚类-k-means-clustering">K-均值聚类 k-means Clustering</h4>
<p>执行聚类任务的算法，用于将数据映射到空间中，起初随机设置 k 个聚类中心在空间里(数量由程序员指定), 各个中心至少一个点。<br />
聚类过程中，每个群里的点都是在所有中心中里所处群中心最近的。完成这样的一次分配后，群中心们会被移到聚类的中心，再迭代一次对各个点的分类，如果某个迭代过程里没有任何点更改自己所处的类，那就完成了任务</p>
<h2 id="神经网络-neural-networks">神经网络 Neural Networks</h2>
<p>AI 神经网络受神经科学的启发。在大脑中，神经元是相互连接的细胞，形成网络。每个神经元都能接收和发送电信号。一旦神经元接收到一定阈值的电输入，神经元就会激活，从而向前发送其电信号。<br />
而人造的神经网络本质上是一种数学模型，由网络状连接起来的数学函数组成，而网络的形状由基于数据的训练形成<br />
每个“神经元”可以视为输入数据和输出数据的映射关系，这也是函数的数学定义，如我们之前提到的预测下雨等任务。<br />
<strong>前馈神经网络 feed-forward neural network</strong>，是最简单的神经网络，各神经元分层排列，每个神经元只与前一层的神经元相连。本课程里介绍的神经网络大多属于此类(除了该章节提到的循环神经网络)</p>
<h3 id="激活函数-activation-functions">激活函数 Activation Functions</h3>
<p><strong>在神经元中，输入的 input 经过一系列加权求和后作用于另一个函数，这个函数就是激活函数</strong>。激活函数最终决定了是否传递信号以及要发射给下一个神经元的内容。<br />
对预测下雨这个离散输出的问题，我们需要某种阈值<br />
例如使用 step function, logistic function(输出连续值表示输出可信度), Rectified Linear Unit (ReLU)(允许任何正值，负数输出强制置 0)</p>
<h3 id="神经网络结构-neural-network-structure">神经网络结构 Neural Network Structure</h3>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/5/nnstructure.png" /> 如图，x1, x2 为输出，边附有一个权值 wi, 连接到输出产生 g，这可以视为一个极小的神经网络</p>
<h3 id="梯度下降-gradient-descent">梯度下降 Gradient Descent</h3>
<p>梯度下降是一种在训练神经网络时最小化损失的算法。如前所述，神经网络能够从数据中推断出有关网络本身结构的知识。到目前为止，我们定义了不同的权重，神经网络允许我们根据训练数据计算这些权重。为了更好地找到合适权重，我们使用梯度下降算法，其工作原理如下：</p>
<ol type="1">
<li>从随机选择权重开始</li>
<li>重复：
<ol type="1">
<li>根据所有数据点计算梯度，从而减少损失。最终，梯度是一个向量</li>
<li>根据梯度更新权重。</li>
</ol></li>
</ol>
<p>根据所有数据计算梯度可能成本较高，为了降低成本，可以使用随机梯度下降 Stochastic Gradient Descent,(根据随机选取的点计算梯度); 小批量梯度下降 Mini-Batch Gradient Descent(基于随机选择的几个点来计算梯度)<br />
当然，输入输出间可以有更复杂的关系，例如根据气压温度等输入给出不同天气的概率, 此时，如下图，每个输入都连接到每个输出，单个输入和任何输出都可以视为一个小规模神经网络，和其他输出分开训练<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/weather.png" /></p>
<h3 id="多层神经网络-multilayer-neural-networks">多层神经网络 Multilayer Neural Networks</h3>
<p>到目前为止，我们的神经网络依赖于 感知器 输出单元。这些单元只能学习线性决策边界，使用直线来分离数据。然而，通常，数据不是线性可分的，在这种情况下，我们转向多层神经网络来对数据进行非线性建模。<br />
多层神经网络是一种具有输入层、输出层和至少一个隐藏层的人工神经网络。<br />
第一个隐藏层中的每个单元从输入层中的每个单元接收加权值，对其执行一些操作并输出一个值。这个过程是自动进行的，不需要人为输入数据。这些值中的每一个都被加权并进一步传播到下一层，重复该过程直到到达输出层。通过隐藏层，可以对非线性数据进行建模。</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/5/multilayer.png" /></p>
<h4 id="反向传播演算法-backpropagation">反向传播演算法 Backpropagation</h4>
<p>反向传播是用于训练具有隐藏层的神经网络的主要算法。<br />
通过从输出单元中的误差开始，计算前一层权重的梯度下降，并重复该过程直到到达输入层来实现。</p>
<ol type="1">
<li>计算输出层的误差</li>
<li>对于每一层，从输出层开始并向内移动到最早的隐藏层：
<ol type="1">
<li>将误差传播回前一层。换句话说，从当前层将错误发送到前一层。</li>
<li>传播的过程中，根据误差更新权重。</li>
</ol></li>
</ol>
<p>这可以扩展到任意数量的隐藏层, 适用于深度神经网络(deep neural networks 有复数个隐藏层)</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/5/deepnn.png" /></p>
<h3 id="过拟合-overfitting-1">过拟合 Overfitting</h3>
<p>对抗过拟合的一种方法是 dropout 去拟合, 临时删除学习过程里的随机单眼，以此方法避免过度依赖网络中的某个单元<br />
训练完成后会再次重新启用整个网络<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/dropout.png" /></p>
<p>下面是实现了反向传播的神经网络库 tensorflow 示例</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data in from file</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;banknotes.csv&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    reader = csv.reader(f)</span><br><span class="line">    <span class="built_in">next</span>(reader)</span><br><span class="line"></span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        data.append(&#123;</span><br><span class="line">            <span class="string">&quot;evidence&quot;</span>: [<span class="built_in">float</span>(cell) <span class="keyword">for</span> cell <span class="keyword">in</span> row[:<span class="number">4</span>]],</span><br><span class="line">            <span class="string">&quot;label&quot;</span>: <span class="number">1</span> <span class="keyword">if</span> row[<span class="number">4</span>] == <span class="string">&quot;0&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate data into training and testing groups</span></span><br><span class="line">evidence = [row[<span class="string">&quot;evidence&quot;</span>] <span class="keyword">for</span> row <span class="keyword">in</span> data]</span><br><span class="line">labels = [row[<span class="string">&quot;label&quot;</span>] <span class="keyword">for</span> row <span class="keyword">in</span> data]</span><br><span class="line">X_training, X_testing, y_training, y_testing = train_test_split(</span><br><span class="line">    evidence, labels, test_size=<span class="number">0.4</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a neural network</span></span><br><span class="line">model = tf.keras.models.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a hidden layer with 8 units, with ReLU activation</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">8</span>, input_shape=(<span class="number">4</span>,), activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add output layer with 1 unit, with sigmoid activation</span></span><br><span class="line">model.add(tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train neural network</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&quot;adam&quot;</span>,</span><br><span class="line">    loss=<span class="string">&quot;binary_crossentropy&quot;</span>,</span><br><span class="line">    metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">)</span><br><span class="line">model.fit(X_training, y_training, epochs=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate how well model performs</span></span><br><span class="line">model.evaluate(X_testing, y_testing, verbose=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="计算机视觉-computer-vision">计算机视觉 Computer Vision</h3>
<p>计算机视觉包含用于分析和理解数字图像的不同计算方法，并且通常使用神经网络来实现。<br />
图像由像素组成，像素由 0 到 255 之间的三个值表示，一为红色，一为绿色，一为蓝色。这些值通常用缩写词 RGB 来表示。我们可以用它来创建一个神经网络，其中每个像素中的每个颜色值都是输入，其中有一些隐藏层，输出是一些单元，这些单元告诉我们图像中显示的内容。<br />
这种方法有一些缺点。首先，通过将图像分解为像素及其颜色值，我们不能使用图像的结构作为辅助。其次，输入的数量非常大，这意味着我们必须计算大量的权重。</p>
<h4 id="图像卷积-image-convolution">图像卷积 Image Convolution</h4>
<p>图像卷积使用一个过滤器 filter ，将图像的每个像素值与其相邻像素值根据内核矩阵的权值乘积相加。这样做会改变图像并可以帮助神经网络处理它。<br />
例如对下图，用右上角的内核矩阵从左侧图像矩阵的左上角 20 开始滚动计算加权和，得到右下角的矩阵<br />
所谓的卷积其实是数学概念，这里先不赘述<br />
此外由于内核矩阵覆盖不到边缘，处理后的图像会小一圈<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/convolution.png" /></p>
<p>不同的内核矩阵有不同的用处，例如下面的矩阵用于提取边缘(这里的想法是: 如果一个点和周边相似，相加就会得到 0)<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/kernel.png" /></p>
<p>PIL library (stands for Python Imaging Library)可以实现图像卷积 <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFilter</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure correct usage</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) != <span class="number">2</span>:</span><br><span class="line">    sys.exit(<span class="string">&quot;Usage: python filter.py filename&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Open image</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(sys.argv[<span class="number">1</span>]).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter image according to edge detection kernel</span></span><br><span class="line">filtered = image.<span class="built_in">filter</span>(ImageFilter.Kernel(</span><br><span class="line">    size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">    kernel=[-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, <span class="number">8</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>],</span><br><span class="line">    scale=<span class="number">1</span></span><br><span class="line">))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show resulting image</span></span><br><span class="line">filtered.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>考虑一下图像的像素数量，计算量依旧很恐怖，一个降低计算量的方法叫池化 Pooling, 通过采样来减少输入量, 即一片区域里选一个像素来计算，如一种方法 Max-Pooling , 选区域里值最高的像素形成一个更小的图像<br />
例如一个 <code>4×4像素矩阵</code> 对 <code>2×2</code> 区域采样的话，最后就得到 <code>2×2</code> 像素矩阵</p>
<h4 id="卷积神经网络-convolutional-neural-networks">卷积神经网络 Convolutional Neural Networks</h4>
<p>卷积神经网络是使用卷积的神经网络，通常用于分析图像。使用过滤器通过不同的内核矩阵来提取图像特征，正如学习权重一样，过滤器也可以通过学习和反馈来提高效果。<br />
最后，汇总提取好的图像，喂给我们的神经网络作为输入数据<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/convolutionalnn.png" /></p>
<p>卷积和池化步骤可以重复多次，以提取额外的特征并减少神经网络输入的大小。这样做还有一个好处是，让神经网络对变化不那么敏感<br />
在代码上，卷积神经网络与传统神经网络没有太大区别。例如以下示例使用 tensorflow 训练卷积网络识别数字</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use MNIST handwriting dataset 即黑白手写数字图片</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare data for training</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line">y_train = tf.keras.utils.to_categorical(y_train)</span><br><span class="line">y_test = tf.keras.utils.to_categorical(y_test)</span><br><span class="line">x_train = x_train.reshape(</span><br><span class="line">    x_train.shape[<span class="number">0</span>], x_train.shape[<span class="number">1</span>], x_train.shape[<span class="number">2</span>], <span class="number">1</span></span><br><span class="line">)</span><br><span class="line">x_test = x_test.reshape(</span><br><span class="line">    x_test.shape[<span class="number">0</span>], x_test.shape[<span class="number">1</span>], x_test.shape[<span class="number">2</span>], <span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a convolutional neural network</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convolutional layer. Learn 32 filters using a 3x3 kernel</span></span><br><span class="line">    tf.keras.layers.Conv2D(</span><br><span class="line">        <span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&quot;relu&quot;</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">    ),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Max-pooling layer, using 2x2 pool size</span></span><br><span class="line">    tf.keras.layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Flatten units</span></span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add a hidden layer with dropout</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    tf.keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add an output layer with output units for all 10 digits</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train neural network</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&quot;adam&quot;</span>,</span><br><span class="line">    loss=<span class="string">&quot;categorical_crossentropy&quot;</span>,</span><br><span class="line">    metrics=[<span class="string">&quot;accuracy&quot;</span>]</span><br><span class="line">)</span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate neural network performance</span></span><br><span class="line">model.evaluate(x_test,  y_test, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># Save model to file</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) == <span class="number">2</span>:</span><br><span class="line">    filename = sys.argv[<span class="number">1</span>]</span><br><span class="line">    model.save(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Model saved to <span class="subst">&#123;filename&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="循环神经网络-recurrent-neural-networks">循环神经网络 Recurrent Neural Networks</h3>
<p>循环神经网络 RNN 由非线性结构组成，也就是说网络可以用自己的输出作为输入。例如微软的 captionbot 能用语句描述图像内容。这与分类不同，因为其输出长度可以根据图像的属性改变，前馈神经网络则无法改变自己的输出数量<br />
而 captioning 能够循环将自己的输出作为输入直到产生满意的结果<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/5/recurrent.png" /></p>
<p>当需要处理数据序列而不是单个对象时，循环神经网络很有用, 翻译任务等也有类似的性质</p>
<h2 id="自然语言处理-natural-language-processing">自然语言处理 Natural Language Processing</h2>
<p>自然语言处理涵盖人工智能获取人类语言作为输入的所有任务。以下是此类任务的一些示例：</p>
<ul>
<li>自动摘要，其中人工智能接受文本作为输入，并生成文本摘要作为输出</li>
<li>信息提取，其中人工智能被给予文本语料库，人工智能提取数据作为输出</li>
<li>语言识别，其中人工智能被给予文本并返回文本的语言作为输出</li>
<li>机器翻译，即向人工智能提供源语言的文本，并输出目标语言的翻译。</li>
<li>命名实体识别，其中人工智能被给予文本，它提取文本中实体的名称（例如，公司名称）</li>
<li>语音识别，人工智能接受语音并在文本中产生相同的单词</li>
<li>文本分类，人工智能收到文本后需要将其分类为某种类型的文本</li>
<li>词义消歧，人工智能需要为具有多种含义的词选择正确的含义</li>
</ul>
<h3 id="句法和语义-syntax-and-semantics">句法和语义 Syntax and Semantics</h3>
<p>句法是句子的结构。对母语者来说下意识就能判断句法正确性，对人工智能或者非母语者来说则不然<br />
语义是单词或句子的含义，就中英文来说，不同句法的句子都可以表示相同的含义，结构正确的句子也可能完全无意义<br />
对人工智能来说，两者都需要掌握</p>
<h4 id="上下文无关语法-context-free-grammar">上下文无关语法 Context-Free Grammar</h4>
<p>形式文法 Formal Grammar 是关于如何用语言生成句子的规则系统。而上下文无关语法则将文本的含义抽象出来，从而用形式文法表示句子的结构<br />
例如句子 <code>She saw the city.</code> 我们首先为每个单词分配其词性。 she 和 city 是名词，我们将其标记为 N。 Saw 是动词，我们将其标记为 V。The 是限定词，将后面的名词标记为定或不定，我们将其标记为 D。上面的句子可以改写为 <code>NVDN</code><br />
那么如何表示这个句子的结构呢，如图，可视为 noun phrase (NP), verb phrase (VP)的组合<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/6/syntactictree.png" /></p>
<p>使用形式文法，人工智能能够表示句子的结构。python 中 nltk 库用于实现这一功能<br />
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line">grammar = nltk.CFG.fromstring(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    S -&gt; NP VP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    NP -&gt; D N | N</span></span><br><span class="line"><span class="string">    VP -&gt; V | V NP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    D -&gt; &quot;the&quot; | &quot;a&quot;</span></span><br><span class="line"><span class="string">    N -&gt; &quot;she&quot; | &quot;city&quot; | &quot;car&quot;</span></span><br><span class="line"><span class="string">    V -&gt; &quot;saw&quot; | &quot;walked&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">parser = nltk.ChartParser(grammar)</span><br><span class="line">sentence = <span class="built_in">input</span>(<span class="string">&quot;Sentence: &quot;</span>).split()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> tree <span class="keyword">in</span> parser.parse(sentence):</span><br><span class="line">        tree.pretty_print()</span><br><span class="line">        tree.draw()</span><br><span class="line"><span class="keyword">except</span> ValueError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;No parse tree possible.&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure> 以上示例代码最后会得到和上图一样的结果</p>
<h4 id="n-元语法-n-grams">n 元语法 n-grams</h4>
<p>一段文本样本中 n 个文本对象的序列就是 n 元语法 ，在 character n-gram 中，对象是字符，word n-gram 中对象是单词<br />
unigram, bigram, and trigram(一元语法，二元语法，三元语法) 可表示 1,2,3 个对象的 n 元语法<br />
例如对下面的句子，前三个三元语法是 “how often have,” “often have I,” and “have I said.”<br />
“How often have I said to you that when you have eliminated the impossible whatever remains, however improbable, must be the truth?”<br />
这种分解方便人工智能记忆和查找，例如输入法推测你下一个可能输入的单词就可以通过这种机制实现</p>
<h4 id="标记化-tokenization">标记化 Tokenization</h4>
<p>将字符序列分割成片段（标记）的任务，标记可以是单词也可以是句子，在这种情况下，任务称为 单词标记化 或 句子标记化 (word tokenization or sentence tokenization)<br />
再分割中，我们会遇到标点符号，符合直觉的想法是一些标点附近的词，如句末，相比其他词更重要。处理这些问题就是标记化的重点任务。</p>
<h4 id="马尔可夫模型-markov-models-1">马尔可夫模型 Markov Models</h4>
<p>基于文本的序列性，使用马尔科夫模型是个符合直觉的想法，例如我们在一段文本上训练模型，不断基于前一个 n 元语法，根据概率计算下一个可能的标记</p>
<h3 id="词袋模型-bag-of-words-model">词袋模型 Bag-of-Words Model</h3>
<p>词袋是一种将文本表示为无序单词集合的模型。该模型忽略语法，仅考虑句子中单词的含义。这种方法对于某些分类任务很有帮助，例如情感分析和区分常规电子邮件与垃圾邮件<br />
考虑这些句子:</p>
<ol type="1">
<li>“My grandson loved it! So much fun!”</li>
<li>“Product broke after a few days.”</li>
<li>“One of the best games I’ve played in a long time.”</li>
<li>“Kind of cheap and flimsy, not worth it.”</li>
</ol>
<p>1,3 中的(“loved,” “fun,” “best”),24 中的 (“broke,” “cheap,” “flimsy”)不难得出答案</p>
<h4 id="naive-bayes">Naive Bayes</h4>
<p>朴素贝叶斯是一种可用于词袋模型情感分析的技术。在情感分析中，问题是“给定句子中的单词，该句子是积极/消极的概率是多少”。<br />
<img src="https://cs50.harvard.edu/ai/2020/notes/6/bayesrule.png" /></p>
<p>假设我们想知道 <code>P(positive | “my grandson loved it”)</code>, 对文本标记化得到 <code>P(positive | “my”, “grandson”, “loved”, “it”)</code>, 使用贝叶斯公式: <code>P(“my”, “grandson”, “loved”, “it” | positive)*P(positive)/P(“my”, “grandson”, “loved”, “it”)</code> 就可以计算答案<br />
鉴于求的是概率，归一化是个自然的想法, 也就是我们只需要考虑分子；而条件概率 P(A|B)与联合概率 P(A, B)成正比，可以进一步化为 <code>P(positive, “my”, “grandson”, “loved”, “it”)*P(positive)</code>, 这个式子算起来会非常麻烦，也就是要算 <code>P(positive)*P(“my” | positive)*P(“grandson” | positive, “my”)*P(loved | positive, “my”, “grandson”)*P(“it” | positive, “my”, “grandson”, “loved”)</code></p>
<p>因此我们需要朴素贝叶斯，朴素(naive)的含义是: 我们假设每个单词的概率独立于其他单词。这不准确，但尽管存在这种不精确性，朴素贝叶斯仍能产生良好的情绪估计。<br />
这样一来只用计算 <code>P(positive)*P(“my” | positive)*P(“grandson” | positive)*P(“loved” | positive)*P(“it” | positive)</code></p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/6/naivebayes.png" /> 我们可能遇到的一个问题是，某些单词可能永远不会出现在某种类型的句子中。例如 P(“grandson” | positive) = 0<br />
解决这个问题的一种方法是使用 <strong>加法平滑 Additive Smoothing</strong>，我们向分布中的每个值添加一个值 α 以平滑数据。这样，即使某个值是 0，通过向其添加 α，我们也不会将肯定句或否定句的整个概率乘以 0。 <strong>拉普拉斯平滑 Laplace Smoothing</strong> 是一种特定类型的加法平滑，它会为我们的每个值添加 1 计数，假装所有值都至少被观察过一次。<br />
假设在文本分类中，有 3 个类，C1、C2、C3，在指定的训练样本中，某个词语 K1，在各个类中观测计数分别为 0，990，10，K1 的概率为 0，0.99，0.01，对这三个量使用拉普拉斯平滑的计算方法如下：<br />
       1/1003 = 0.001，991/1003 = 0.988，11/1003 = 0.011</p>
<h4 id="信息检索-information-retrieval">信息检索 Information Retrieval</h4>
<p>信息检索是响应用户查询查找相关文档的任务。我们使用 <strong>主题建模 topic modeling</strong> 来发现一组文档的主题<br />
人工智能如何提取文档主题？一种方法是查看 <strong>术语频率 term frequency</strong>，即简单地计算术语在文档中出现的次数<br />
一般来说我们追求所谓的内容词 content words，也就是信息含量比较高的词，而不是 <strong>功能词 function words</strong><br />
指标 <strong>逆文档频率 Inverse Document Frequency</strong>，用于衡量一个词在语料库中的文档中的常见或罕见程度。通常通过以下等式计算： <img src="https://cs50.harvard.edu/ai/2020/notes/6/idf.png" /><br />
tf-idf(库)表示 Term Frequency — Inverse Document Frequency.即将每个单词的术语频率乘以逆文档频率，从而获得每个单词的值，一个词在一份文档中出现的频率越高、出现的文档越少，其值就越高。 TFIDF 的主要思想是：如果某个词或短语在一篇文章中出现的频率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。</p>
<h3 id="信息提取-information-extraction">信息提取 Information Extraction</h3>
<p>信息抽取是从文档中抽取知识的任务。到目前为止，当我们希望人工智能执行简单的任务时，例如识别句子中的情绪是积极的还是消极的，或者检索文档中的关键词，使用词袋方法处理文本很有帮助。然而，对于像信息提取这样的任务，我们需要人工智能来理解不同单词之间的联系，词袋方法就不太实用了<br />
信息提取的可能任务可以采取以下形式：向人工智能提供文档作为输入，并获取公司列表及其成立年份作为输出。最符合直接的可能给 ai 一个模板让其匹配，但并非所有数据都按模板给出，因此可以给人工智能一个抽象的例子，比如“Facebook，2004”，并让它开发自己的模型来提取数据。<br />
总之，我们需要 ai 能某种程度上能理解词语之间的关系</p>
<h4 id="词网-word-net">词网 Word Net</h4>
<p>Wordnet 是一个类似于字典的数据库，其中为单词提供了定义以及更广泛的类别。例如，“房屋”一词会产生多种定义，其中之一是“为一个或多个家庭提供居住区的住宅”。该定义与“建筑”和“住宅”类别配对。</p>
<h4 id="词汇表征-word-representation">词汇表征 Word Representation</h4>
<p>我们希望在人工智能中表示单词的含义。正如我们之前所看到的，以数字形式向人工智能提供输入是很方便的, 即 <strong>词嵌入（Word Embedding）</strong>(将文本中的单词映射到向量空间中)。这种向量称为词向量</p>
<p>对小文本可以使用独热编码 One-Hot Representation，即 N 位信息来对 N 个状态进行编码，每个单词都用一个向量表示，该向量由与文本总单词数量个维度组成。<br />
句子 <code>He wrote a book</code> 可以这么表示:</p>
<ul>
<li>[1, 0, 0, 0] (he)</li>
<li>[0, 1, 0, 0] (wrote)</li>
<li>[0, 0, 1, 0] (a)</li>
<li>[0, 0, 0, 1] (book)</li>
</ul>
<p>对规模更大的文本，可以使用分布式表示 Distributed Representation , 向量的每个维度表示某种程度上的语义，例如:</p>
<ul>
<li>[-0.34, -0.08, 0.02, -0.18, …] (he)</li>
<li>[-0.27, 0.40, 0.00, -0.65, …] (wrote)</li>
<li>[-0.12, -0.25, 0.29, -0.09, …] (a)</li>
<li>[-0.23, -0.16, -0.05, -0.57, …] (book)</li>
</ul>
<p>另一个好处是：我们也可以用周围的词义来优化一个单词的词义向量</p>
<h4 id="word2vec">word2vec</h4>
<p>一种用于生成单词的分布式表示的算法。<br />
word2vec 使用 Skip-Gram 架构 ，一种神经网络架构，用于预测给定目标单词的上下文。在这种架构中，神经网络对于每个目标词都有一个输入单元。较小的单个隐藏层（例如 50 或 100 个单元）将生成表示单词的分布式表示的值。该隐藏层中的每个单元都连接到输入层中的每个单元。输出层将生成可能出现在与目标单词相似的上下文中的单词。与我们在上一讲中看到的类似，该网络需要使用反向传播算法使用训练数据集进行训练。<br />
即该模型可以用单个词预测上下文，也可以反过来用上下文填空</p>
<p><img src="https://cs50.harvard.edu/ai/2020/notes/6/sgarchitecture.png" /></p>
<p>这么一来我们可以方便地查找相似向量的单词，例如对单词 book: books, essay, memoir, essays, novella, anthology, blurb, autobiography, audiobook<br />
此外，king and man, queen and woman 的差异是相似的，考虑日本和拉面，用到美国上就会得到墨西哥卷饼(话说为什么不是汉堡)</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" rel="tag"><i class="fa fa-tag"></i> 课程笔记</a>
              <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
              <a href="/tags/%E5%93%88%E4%BD%9B/" rel="tag"><i class="fa fa-tag"></i> 哈佛</a>
              <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag"><i class="fa fa-tag"></i> 人工智能</a>
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AE%89%E5%85%A8/" rel="tag"><i class="fa fa-tag"></i> 计算机安全</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
      <a class="a2a_button_wechat"></a>
      <a class="a2a_button_qzone"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/thinklive/3231/" rel="prev" title="基于赫尔辛基大学《深入浅出现代Web编程》的web笔记">
                  <i class="fa fa-angle-left"></i> 基于赫尔辛基大学《深入浅出现代Web编程》的web笔记
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/thinklive/48061/" rel="next" title="机器学习笔记 all in one">
                  机器学习笔记 all in one <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">thinklive</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">618k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">37:27</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 技术支持
  </div><script defer src="/lib/three.js"></script><script defer src="/lib/lines.js"></script><script defer src="/lib/waves.js"></script>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.24/fancybox/fancybox.umd.js" integrity="sha256-oyhjPiYRWGXaAt+ny/mTMWOnN1GBoZDUQnzzgC7FRI4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>


  <script src=""></script>
  <script src="/%5Bobject%20Object%5D"></script>
  <script src="/%5Bobject%20Object%5D"></script>
  <script src="/%5Bobject%20Object%5D"></script>
  <script src="/%5Bobject%20Object%5D"></script>


<script>
var options = {
  bottom: '64px', // default: '32px'
  right: 'unset', // default: '32px'
  left: '32px', // default: 'unset'
  time: '0.5s', // default: '0.3s'
  mixColor: '#fff', // default: '#fff'
  backgroundColor: '#fff',  // default: '#fff'
  buttonColorDark: '#100f2c',  // default: '#100f2c'
  buttonColorLight: '#fff', // default: '#fff'
  saveInCookies: true, // default: true,
  label: '🌓', // default: ''
  autoMatchOsTheme: true // default: true
}
const darkmode = new Darkmode(options);
darkmode.showWidget();
</script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js","integrity":"sha256-g2xji1rlE3KsGVClvuxTbcR0Kn2+wtQADSff2Tbb4zA="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>


  <script class="next-config" data-name="wavedrom" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.3.0/wavedrom.min.js","integrity":"sha256-IRMDzTC+wK5stMucZ/XSXkeS5VNtxZ+/Bm8Mcqfoxdo="}}</script>
  <script class="next-config" data-name="wavedrom_skin" type="application/json">{"enable":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/wavedrom/3.3.0/skins/default.js","integrity":"sha256-fduc/Zszk5ezWws2uInY/ALWVmIrmV6VTgXbsYSReFI="}}</script>
  <script src="/js/third-party/tags/wavedrom.js"></script>

  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  <script src="/js/third-party/addtoany.js"></script>

  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://thinklive1.github.io/thinklive/16959/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"thinklive1/blog_comments","issue_term":"pathname","theme":"photon-dark"}</script>
<script src="/js/third-party/comments/utterances.js"></script>
<script>
    const snowflakes = ["❄", "❄", "❆", "❅", "✥","❄", "❄", "❆", "❅", "✥","✻"];
    // 创建雪花
    function createSnowflake() {
        const snowflake = document.createElement("span");
        snowflake.classList.add("snowflake");
        const randomIndex = Math.floor(Math.random() * snowflakes.length);
        snowflake.textContent = snowflakes[randomIndex];
        
        // 起始位置
        /* 80%概率 生成在页面两侧 30% 的位置
        const probability = Math.random();
        let startPosition = Math.random() * 100;

        if (probability < 0.8) {
            startPosition = Math.random() < 0.5 ? Math.random() * 30 : (Math.random() * 30) + 70;
        }
        snowflake.style.left = `${startPosition}vw`;
        */
        snowflake.style.left = `${Math.random() * 100}vw`;
        snowflake.style.top = `-30px`;
        // 雪花大小与透明度
        const size = Math.random() * 18 + 10;
        snowflake.style.fontSize = `${size}px`;
        const opacity = Math.random() * 0.6 + (size > 18 ? 0.4 : 0);
        snowflake.style.setProperty("--opacity", opacity);
        // 动画持续时间
        const fallDuration = Math.random() * 10 + 10;
        // 旋转持续时间
        const rotateDuration = Math.random() * 3 + 1;

        snowflake.style.animationDuration = `${fallDuration}s, ${fallDuration}s`; // 向 CSS 添加淡出动画的持续时间
        // 横向幅度
        const translateX = (Math.random() * 500 - 200);
        snowflake.style.setProperty("--translateX", `${translateX}px`);
        // 纵向幅度
        snowflake.style.setProperty("--translateY", `${window.innerHeight}px`);

        document.body.appendChild(snowflake);
        // 移除雪花
        setTimeout(() => {
            snowflake.remove();
        }, fallDuration * 1000);
    }
    
    function snowfallAnimation() {
        // 载入时若边栏是隐藏状态则不加载雪花
        const sidebarnav = document.querySelector('.sidebar');
        const sidebarnavdisplay = window.getComputedStyle(sidebarnav).getPropertyValue('display'); 
        if (sidebarnavdisplay !== 'none') {
            createSnowflake();
        }
        setTimeout(snowfallAnimation, 500); // 生成速度，毫秒
    }
    snowfallAnimation();
function toggleMode() {
    console.log("change color!");
    const root1 = document.documentElement;

    // 检查当前 color-scheme
    const isLightMode = getComputedStyle(root1).getPropertyValue('--content-bg-color').trim() === '#fff';

    if (isLightMode) {
        // 切换到暗模式
        const images = document.querySelectorAll('img'); // 选择所有<img>标签
        images.forEach(img => {
            img.style.filter = 'brightness(50%)'; // 设置亮度为50%
        });

        root1.style.setProperty('--content-bg-color', '#333');
        root1.style.setProperty('--link-color', '#aaa');
        root1.style.setProperty('--text-color', '#fff');
        root1.style.setProperty('--highlight-background', '#444');
        root1.style.setProperty('--highlight-foreground', '#bbb');
        root1.style.setProperty('--btn-default-bg', '#777');
        root1.style.setProperty('--menu-item-bg-color', '#777');
        root1.style.setProperty('--table-row-odd-bg-color', '#444');
        root1.style.setProperty('--note-warning-bg-color', '#555');
        root1.style.setProperty('--note-bg-color', '#555');
        root1.style.setProperty('--note-info-bg-color', '#555');
        root1.style.setProperty('--highlight-gutter-foreground', '#98d9ffff');
        root1.style.setProperty('', '#777');
        root1.style.transition = 'all 0.5s ease';

    }

    else {
        const images = document.querySelectorAll('img'); // 选择所有<img>标签
        images.forEach(img => {
            img.style.filter = 'brightness(100%)'; // 设置亮度为50%
        });
        root1.style.setProperty('--content-bg-color', '#fff');
        root1.style.setProperty('--text-color', '#555');
        root1.style.setProperty('--highlight-background', '#eaeef3');
        root1.style.setProperty('--highlight-foreground', '#00193a');
        root1.style.setProperty('--btn-default-bg', '#fff');
        root1.style.setProperty('--menu-item-bg-color', '#f5f5f5');
        root1.style.setProperty('--note-warning-bg-color', '#fdf8ea');
        root1.style.setProperty('--note-bg-color', '#f9f9f9');
        root1.style.setProperty('--note-info-bg-color', '#eef7fa');
        root1.style.setProperty('--table-row-odd-bg-color', '#f9f9f9');
        root1.style.setProperty('--highlight-gutter-foreground', '#172e4c');
        root1.style.transition = 'all 0.5s ease';
    }
}

function DarkTrigger() {
    console.log('dark!!')
    let isDarkMode = getComputedStyle(document.documentElement).getPropertyValue('--content-bg-color').trim() === '#000';
    console.log(isDarkMode)
    if (isDarkMode) {
        // 切换到暗模式
        const warningNotes = document.querySelectorAll('.post-body .note.warning');
        // 修改背景颜色
        warningNotes.forEach(note => {
        note.style.background = '#666';
        });

        const infoNotes = document.querySelectorAll('.post-body .note.info');
        // 修改背景颜色
        infoNotes.forEach(note => {
        note.style.background = '#666';
        });
    }
}


</script>

 <!--js: 线条特效-->
  <script type="text/javascript" color="255,255,255" opacity='1' zIndex="-1" count="50" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>

<button style="background: #868686;
  width: 3rem;
  height: 3rem;
  position: fixed;
  border-radius: 50%;
  border: none;
  right: unset;
  bottom: 2rem;
  left: 2rem;
  cursor: pointer;
  transition: all 0.5s ease;
  display: flex;
  justify-content: center;
  align-items: center;" class="darkmode-toggle" role="checkbox" onclick="toggleMode()">🌓</button>

  <video autoplay loop muted playsinline style="position:fixed;top:50%;opacity: 0.8;left:50%;min-width:100%;min-height:100%;transform:translateX(-50%)translateY(-50%);z-index:-2;">
  <source src="/images/red.mp4" type="video/mp4">
<!-- hexo injector body_end start --><script src="/assets/mmedia/mmedia-loader.js"></script><!-- hexo injector body_end end --></body>
</html>
